{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.PyTorch的核心是两个主要特征：\n",
    "* 一个n维张量，类似于numpy，但可以在GPU上运行\n",
    "* 搭建和训练神经网络时的自动微分/求导机制\n",
    "\n",
    "### 2.张量\n",
    "#### 2.1 Numpy\n",
    "* Numpy提供了一个n维数组对象，以及许多用于操作这些数组的函数\n",
    "* 是用于科学计算的通用框架\n",
    "* 使用NumPy，可以较为容易的手动实现网络的前向和反向传播，从而拟合随机数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss:  30433360.446173325\n",
      " loss:  29454548.444982637\n",
      " loss:  33986063.62629625\n",
      " loss:  38041766.64363592\n",
      " loss:  35855162.825265855\n",
      " loss:  25735332.901504956\n",
      " loss:  14146137.874278465\n",
      " loss:  6531046.780652863\n",
      " loss:  3017961.737330654\n",
      " loss:  1598606.1338415146\n",
      " loss:  1015706.2072119865\n",
      " loss:  741172.2984830884\n",
      " loss:  585938.0257086998\n",
      " loss:  482436.4084289622\n",
      " loss:  405458.3870712052\n",
      " loss:  344839.7246098875\n",
      " loss:  295601.79695359076\n",
      " loss:  254940.87016952955\n",
      " loss:  221101.7678161362\n",
      " loss:  192570.3205399569\n",
      " loss:  168383.1933735331\n",
      " loss:  147753.82544844615\n",
      " loss:  130064.38113091455\n",
      " loss:  114834.70799684449\n",
      " loss:  101669.70033602024\n",
      " loss:  90228.63544405081\n",
      " loss:  80264.45671714004\n",
      " loss:  71555.12490618404\n",
      " loss:  63916.02685362147\n",
      " loss:  57198.00007365936\n",
      " loss:  51277.74907304211\n",
      " loss:  46045.41040893754\n",
      " loss:  41407.98586476202\n",
      " loss:  37293.93954347222\n",
      " loss:  33633.50254412526\n",
      " loss:  30368.747490482332\n",
      " loss:  27455.937381279015\n",
      " loss:  24851.74015046691\n",
      " loss:  22518.45436472742\n",
      " loss:  20424.273654068507\n",
      " loss:  18541.971735775645\n",
      " loss:  16851.73404372576\n",
      " loss:  15329.51215768729\n",
      " loss:  13956.019877340803\n",
      " loss:  12715.640208032257\n",
      " loss:  11594.64716033905\n",
      " loss:  10580.413336394551\n",
      " loss:  9662.039828190887\n",
      " loss:  8829.029762907703\n",
      " loss:  8073.649088877749\n",
      " loss:  7387.000489489014\n",
      " loss:  6763.4049338084005\n",
      " loss:  6196.025611317596\n",
      " loss:  5679.278657801791\n",
      " loss:  5208.471349069225\n",
      " loss:  4779.345684872054\n",
      " loss:  4387.890908315863\n",
      " loss:  4030.4778898166624\n",
      " loss:  3704.009429677862\n",
      " loss:  3405.4004377601805\n",
      " loss:  3132.110960496894\n",
      " loss:  2881.9894290231637\n",
      " loss:  2652.8615097596185\n",
      " loss:  2442.9321490434477\n",
      " loss:  2250.3910499840154\n",
      " loss:  2073.7324199498166\n",
      " loss:  1911.6625749268567\n",
      " loss:  1762.907369223893\n",
      " loss:  1626.2501815479457\n",
      " loss:  1500.5798837058198\n",
      " loss:  1385.0864925661413\n",
      " loss:  1278.9116962736066\n",
      " loss:  1181.2087694508823\n",
      " loss:  1091.2908551412788\n",
      " loss:  1008.5122913296506\n",
      " loss:  932.230310642646\n",
      " loss:  861.9231095023995\n",
      " loss:  797.1295851544841\n",
      " loss:  737.4085025557664\n",
      " loss:  682.308464196966\n",
      " loss:  631.4745759724633\n",
      " loss:  584.5608250468775\n",
      " loss:  541.2390372058812\n",
      " loss:  501.2496716041089\n",
      " loss:  464.30712283662126\n",
      " loss:  430.16330478976477\n",
      " loss:  398.61468694872565\n",
      " loss:  369.4589025568757\n",
      " loss:  342.4922460022739\n",
      " loss:  317.5597588444251\n",
      " loss:  294.4926889290854\n",
      " loss:  273.14539729585846\n",
      " loss:  253.3879051823767\n",
      " loss:  235.10149078756825\n",
      " loss:  218.1789582570196\n",
      " loss:  202.50518088971413\n",
      " loss:  187.98482082986033\n",
      " loss:  174.53979913652176\n",
      " loss:  162.07337875444057\n",
      " loss:  150.51772321775104\n",
      " loss:  139.80626365526268\n",
      " loss:  129.88232983512304\n",
      " loss:  120.6732274121095\n",
      " loss:  112.13383591458663\n",
      " loss:  104.21158667482823\n",
      " loss:  96.86342438409946\n",
      " loss:  90.04629093649407\n",
      " loss:  83.72036149345104\n",
      " loss:  77.84936261897012\n",
      " loss:  72.39668691901332\n",
      " loss:  67.33533800997171\n",
      " loss:  62.63524742422304\n",
      " loss:  58.27053919262819\n",
      " loss:  54.21498849119945\n",
      " loss:  50.44836912719683\n",
      " loss:  46.949680196634176\n",
      " loss:  43.697259613180506\n",
      " loss:  40.67435094357228\n",
      " loss:  37.864569731321225\n",
      " loss:  35.252869635770345\n",
      " loss:  32.82473596353057\n",
      " loss:  30.566923269322217\n",
      " loss:  28.467485286451566\n",
      " loss:  26.516392486869787\n",
      " loss:  24.700202544868283\n",
      " loss:  23.01062419268515\n",
      " loss:  21.438668001363098\n",
      " loss:  19.975837784013677\n",
      " loss:  18.61443909621754\n",
      " loss:  17.347619773897897\n",
      " loss:  16.1682991017353\n",
      " loss:  15.070488947285057\n",
      " loss:  14.048390732847867\n",
      " loss:  13.096843982126988\n",
      " loss:  12.211080124027102\n",
      " loss:  11.386316079795053\n",
      " loss:  10.61798541372108\n",
      " loss:  9.902063705732022\n",
      " loss:  9.235165818574695\n",
      " loss:  8.614232775236726\n",
      " loss:  8.035452054754984\n",
      " loss:  7.496064054813225\n",
      " loss:  6.99365990369917\n",
      " loss:  6.525331460179429\n",
      " loss:  6.088987300824064\n",
      " loss:  5.682175995521808\n",
      " loss:  5.302870429078446\n",
      " loss:  4.949241342221036\n",
      " loss:  4.619532034415445\n",
      " loss:  4.312229835204751\n",
      " loss:  4.025537272541779\n",
      " loss:  3.758199473609779\n",
      " loss:  3.50890226490801\n",
      " loss:  3.276392494515049\n",
      " loss:  3.05959562781124\n",
      " loss:  2.8572512888583423\n",
      " loss:  2.6684721255819897\n",
      " loss:  2.4923018019966294\n",
      " loss:  2.3279031772550933\n",
      " loss:  2.1745159942660175\n",
      " loss:  2.0313806218651718\n",
      " loss:  1.8977923691774885\n",
      " loss:  1.7731008236728731\n",
      " loss:  1.6567161542646984\n",
      " loss:  1.548081343568184\n",
      " loss:  1.446664864402621\n",
      " loss:  1.3519253263148487\n",
      " loss:  1.263478245410858\n",
      " loss:  1.1809166663528567\n",
      " loss:  1.1038049111682455\n",
      " loss:  1.031787254970022\n",
      " loss:  0.9645241638908586\n",
      " loss:  0.9017227884960792\n",
      " loss:  0.8430609581965393\n",
      " loss:  0.7882541113272257\n",
      " loss:  0.7370496662447356\n",
      " loss:  0.6892161173037734\n",
      " loss:  0.6445155244707413\n",
      " loss:  0.6027545148759872\n",
      " loss:  0.5637220163486777\n",
      " loss:  0.527254139262805\n",
      " loss:  0.49318014644546626\n",
      " loss:  0.46131778901929577\n",
      " loss:  0.4315463353939898\n",
      " loss:  0.4037369820983979\n",
      " loss:  0.3777189643184684\n",
      " loss:  0.3533967614320548\n",
      " loss:  0.33065615324760445\n",
      " loss:  0.30940058243918306\n",
      " loss:  0.2895290484441969\n",
      " loss:  0.27094740721296007\n",
      " loss:  0.2535683613432609\n",
      " loss:  0.23731537108687695\n",
      " loss:  0.22211601440705267\n",
      " loss:  0.20790071305123842\n",
      " loss:  0.19460323317953576\n",
      " loss:  0.18216826585582957\n",
      " loss:  0.17053634077849505\n",
      " loss:  0.1596509846917814\n",
      " loss:  0.14946843759298067\n",
      " loss:  0.13994270277932824\n",
      " loss:  0.13103246443620217\n",
      " loss:  0.12269353969428594\n",
      " loss:  0.11489064604580694\n",
      " loss:  0.10758985757873601\n",
      " loss:  0.10075860818049034\n",
      " loss:  0.0943639419136566\n",
      " loss:  0.0883784678537312\n",
      " loss:  0.08277886947698318\n",
      " loss:  0.07753643706231236\n",
      " loss:  0.07262762671823984\n",
      " loss:  0.0680342210036626\n",
      " loss:  0.06373581104780895\n",
      " loss:  0.05970972558093593\n",
      " loss:  0.05593965054625226\n",
      " loss:  0.05241148707122174\n",
      " loss:  0.04910668117582966\n",
      " loss:  0.046012570355156754\n",
      " loss:  0.04311495680778472\n",
      " loss:  0.0404013665177385\n",
      " loss:  0.037859901255340125\n",
      " loss:  0.03548065314375177\n",
      " loss:  0.033251812039514404\n",
      " loss:  0.031163935971866917\n",
      " loss:  0.029208716778035257\n",
      " loss:  0.027377528472327606\n",
      " loss:  0.025662439178971992\n",
      " loss:  0.024055072745975847\n",
      " loss:  0.022549290573377324\n",
      " loss:  0.02113883804972165\n",
      " loss:  0.019817181763768493\n",
      " loss:  0.018578618473472232\n",
      " loss:  0.01741822312672888\n",
      " loss:  0.01633133399441483\n",
      " loss:  0.01531242340614996\n",
      " loss:  0.014357830909283196\n",
      " loss:  0.013463202718616684\n",
      " loss:  0.012624776344119154\n",
      " loss:  0.011838997480325865\n",
      " loss:  0.011102839022375695\n",
      " loss:  0.010412633366024255\n",
      " loss:  0.009765747350703537\n",
      " loss:  0.009159118853404175\n",
      " loss:  0.008590588023200493\n",
      " loss:  0.00805756327290532\n",
      " loss:  0.0075578856634407835\n",
      " loss:  0.007089533608886869\n",
      " loss:  0.006650474520042863\n",
      " loss:  0.006238608956377283\n",
      " loss:  0.005852535632805439\n",
      " loss:  0.005490525500071433\n",
      " loss:  0.0051510807492839514\n",
      " loss:  0.0048327553973934075\n",
      " loss:  0.004534351445365176\n",
      " loss:  0.0042544341765598384\n",
      " loss:  0.0039918876788325374\n",
      " loss:  0.0037456553229447114\n",
      " loss:  0.0035147951570173638\n",
      " loss:  0.0032982576226893165\n",
      " loss:  0.0030951593668450588\n",
      " loss:  0.0029046563838594345\n",
      " loss:  0.00272594982200539\n",
      " loss:  0.0025583133357529077\n",
      " loss:  0.002401048442190242\n",
      " loss:  0.00225352335650429\n",
      " loss:  0.002115230611496602\n",
      " loss:  0.0019854065327092867\n",
      " loss:  0.0018635806324702586\n",
      " loss:  0.0017492870621850097\n",
      " loss:  0.0016420380711276883\n",
      " loss:  0.0015414396294777652\n",
      " loss:  0.001447011416368378\n",
      " loss:  0.0013584165568249367\n",
      " loss:  0.0012752781729692794\n",
      " loss:  0.0011972737076403565\n",
      " loss:  0.001124070633100474\n",
      " loss:  0.0010553758543091459\n",
      " loss:  0.0009908954973450197\n",
      " loss:  0.0009304018536592505\n",
      " loss:  0.0008735966447714592\n",
      " loss:  0.0008202871136552562\n",
      " loss:  0.0007702553349526119\n",
      " loss:  0.0007232948194444738\n",
      " loss:  0.0006792099506662405\n",
      " loss:  0.0006378296743018852\n",
      " loss:  0.0005989934869183902\n",
      " loss:  0.00056254046548594\n",
      " loss:  0.000528302964258923\n",
      " loss:  0.0004961684917162677\n",
      " loss:  0.0004659979722273404\n",
      " loss:  0.0004376890055134114\n",
      " loss:  0.0004111094685481508\n",
      " loss:  0.0003861362564158276\n",
      " loss:  0.0003626946709475087\n",
      " loss:  0.00034068513894681827\n",
      " loss:  0.0003200177058501428\n",
      " loss:  0.000300616708125712\n",
      " loss:  0.0002823906695570235\n",
      " loss:  0.00026527869584764803\n",
      " loss:  0.00024920803508863805\n",
      " loss:  0.000234116367344648\n",
      " loss:  0.00021994365895350358\n",
      " loss:  0.00020663599076847802\n",
      " loss:  0.0001941350079196981\n",
      " loss:  0.00018239358387703135\n",
      " loss:  0.0001713675184409523\n",
      " loss:  0.00016101243551419676\n",
      " loss:  0.00015128708763927263\n",
      " loss:  0.00014215030862824087\n",
      " loss:  0.00013357049307506842\n",
      " loss:  0.00012551078414840074\n",
      " loss:  0.00011793814171497555\n",
      " loss:  0.00011082481558639334\n",
      " loss:  0.00010414290123829082\n",
      " loss:  9.786688466858904e-05\n",
      " loss:  9.197407657959348e-05\n",
      " loss:  8.64336161654505e-05\n",
      " loss:  8.122850053753891e-05\n",
      " loss:  7.634043908547587e-05\n",
      " loss:  7.174761675309653e-05\n",
      " loss:  6.743083224928106e-05\n",
      " loss:  6.33749875428101e-05\n",
      " loss:  5.956535551962839e-05\n",
      " loss:  5.598548686928248e-05\n",
      " loss:  5.262178980350092e-05\n",
      " loss:  4.9460973683750615e-05\n",
      " loss:  4.6490994965217086e-05\n",
      " loss:  4.369990469321109e-05\n",
      " loss:  4.107747026149208e-05\n",
      " loss:  3.861355956245555e-05\n",
      " loss:  3.629769515295685e-05\n",
      " loss:  3.412105848413101e-05\n",
      " loss:  3.207584675126307e-05\n",
      " loss:  3.01534602323193e-05\n",
      " loss:  2.834711883686669e-05\n",
      " loss:  2.6649143720404604e-05\n",
      " loss:  2.5053509563686008e-05\n",
      " loss:  2.3553570418444124e-05\n",
      " loss:  2.214481003452589e-05\n",
      " loss:  2.0820496807403756e-05\n",
      " loss:  1.9575544907109646e-05\n",
      " loss:  1.8404860835669785e-05\n",
      " loss:  1.7304761793402657e-05\n",
      " loss:  1.6270428564380468e-05\n",
      " loss:  1.5298417859692067e-05\n",
      " loss:  1.4384485259463901e-05\n",
      " loss:  1.3525499689955534e-05\n",
      " loss:  1.2717920334771873e-05\n",
      " loss:  1.1958858174988245e-05\n",
      " loss:  1.1245272155197694e-05\n",
      " loss:  1.0574467047455293e-05\n",
      " loss:  9.94388124352513e-06\n",
      " loss:  9.35099237946127e-06\n",
      " loss:  8.79354976278968e-06\n",
      " loss:  8.269598806103698e-06\n",
      " loss:  7.776834195682374e-06\n",
      " loss:  7.313559480452773e-06\n",
      " loss:  6.877955466953214e-06\n",
      " loss:  6.468475752018195e-06\n",
      " loss:  6.083475082844348e-06\n",
      " loss:  5.7214206706734155e-06\n",
      " loss:  5.381154670436321e-06\n",
      " loss:  5.061200123034387e-06\n",
      " loss:  4.760249584281632e-06\n",
      " loss:  4.477183699609018e-06\n",
      " loss:  4.211014929488345e-06\n",
      " loss:  3.960787273925514e-06\n",
      " loss:  3.7254739031299684e-06\n",
      " loss:  3.5041694107480534e-06\n",
      " loss:  3.296047626222302e-06\n",
      " loss:  3.1003870253282797e-06\n",
      " loss:  2.9163152462119246e-06\n",
      " loss:  2.743222671748372e-06\n",
      " loss:  2.5804799130181053e-06\n",
      " loss:  2.4274098645330552e-06\n",
      " loss:  2.2834195018267193e-06\n",
      " loss:  2.147995485470996e-06\n",
      " loss:  2.0206611215900794e-06\n",
      " loss:  1.900891838789627e-06\n",
      " loss:  1.7882327721774097e-06\n",
      " loss:  1.6822844041127241e-06\n",
      " loss:  1.5826438662498434e-06\n",
      " loss:  1.4889156073063712e-06\n",
      " loss:  1.4007683217938433e-06\n",
      " loss:  1.317895220284602e-06\n",
      " loss:  1.2398797617897154e-06\n",
      " loss:  1.166511933877633e-06\n",
      " loss:  1.0974980161552722e-06\n",
      " loss:  1.032566436320079e-06\n",
      " loss:  9.714937203159467e-07\n",
      " loss:  9.140633231721037e-07\n",
      " loss:  8.600182741300732e-07\n",
      " loss:  8.09175877628931e-07\n",
      " loss:  7.61356206004846e-07\n",
      " loss:  7.163826681543856e-07\n",
      " loss:  6.740689594300354e-07\n",
      " loss:  6.342542780303117e-07\n",
      " loss:  5.967984933649143e-07\n",
      " loss:  5.61562493852598e-07\n",
      " loss:  5.284146509151766e-07\n",
      " loss:  4.972258142590081e-07\n",
      " loss:  4.678814835278104e-07\n",
      " loss:  4.402785302848831e-07\n",
      " loss:  4.143076830364585e-07\n",
      " loss:  3.898688115812477e-07\n",
      " loss:  3.668804333561382e-07\n",
      " loss:  3.4527049321116887e-07\n",
      " loss:  3.2491935931817234e-07\n",
      " loss:  3.057683330045005e-07\n",
      " loss:  2.877521364023102e-07\n",
      " loss:  2.7079780390896857e-07\n",
      " loss:  2.5484542184002216e-07\n",
      " loss:  2.398354279068174e-07\n",
      " loss:  2.2571136319831693e-07\n",
      " loss:  2.124220608601783e-07\n",
      " loss:  1.9991752340761538e-07\n",
      " loss:  1.8814898016878035e-07\n",
      " loss:  1.770792735578206e-07\n",
      " loss:  1.6666152180930602e-07\n",
      " loss:  1.5685727322189605e-07\n",
      " loss:  1.4763119009687e-07\n",
      " loss:  1.3894950894247204e-07\n",
      " loss:  1.3077807856643491e-07\n",
      " loss:  1.2308955193323005e-07\n",
      " loss:  1.1585323215190144e-07\n",
      " loss:  1.0904445609702087e-07\n",
      " loss:  1.0263648551652751e-07\n",
      " loss:  9.660599205953602e-08\n",
      " loss:  9.09350508342342e-08\n",
      " loss:  8.559419463586788e-08\n",
      " loss:  8.056696152973071e-08\n",
      " loss:  7.583641401862627e-08\n",
      " loss:  7.138414948209322e-08\n",
      " loss:  6.719359065771823e-08\n",
      " loss:  6.324993322407626e-08\n",
      " loss:  5.953753122321591e-08\n",
      " loss:  5.604395291495474e-08\n",
      " loss:  5.275626841372412e-08\n",
      " loss:  4.966135319123957e-08\n",
      " loss:  4.67491004476912e-08\n",
      " loss:  4.400758633251898e-08\n",
      " loss:  4.1427092128642885e-08\n",
      " loss:  3.899842059233987e-08\n",
      " loss:  3.6712382107219225e-08\n",
      " loss:  3.456092355587171e-08\n",
      " loss:  3.253549678632393e-08\n",
      " loss:  3.0628865182757075e-08\n",
      " loss:  2.8834531099794198e-08\n",
      " loss:  2.7145473181250414e-08\n",
      " loss:  2.555619585980063e-08\n",
      " loss:  2.405986757809808e-08\n",
      " loss:  2.265099006979713e-08\n",
      " loss:  2.1325008543223964e-08\n",
      " loss:  2.00764804665218e-08\n",
      " loss:  1.890138265934584e-08\n",
      " loss:  1.779534429465657e-08\n",
      " loss:  1.6754052754632633e-08\n",
      " loss:  1.5773751630105602e-08\n",
      " loss:  1.4850834654210736e-08\n",
      " loss:  1.3982236183586336e-08\n",
      " loss:  1.3164386545687239e-08\n",
      " loss:  1.239455375111964e-08\n",
      " loss:  1.1669840670738782e-08\n",
      " loss:  1.09875863782455e-08\n",
      " loss:  1.034524953636991e-08\n",
      " loss:  9.740502970841355e-09\n",
      " loss:  9.171368311520808e-09\n",
      " loss:  8.635428207447517e-09\n",
      " loss:  8.130850978999367e-09\n",
      " loss:  7.655886328904352e-09\n",
      " loss:  7.208825926393027e-09\n",
      " loss:  6.787784756303227e-09\n",
      " loss:  6.391326209480938e-09\n",
      " loss:  6.01815965975739e-09\n",
      " loss:  5.666759833931792e-09\n",
      " loss:  5.3359455235919394e-09\n",
      " loss:  5.024425565298302e-09\n",
      " loss:  4.73120101184464e-09\n",
      " loss:  4.455097779253775e-09\n",
      " loss:  4.195103879682155e-09\n",
      " loss:  3.950312477179473e-09\n",
      " loss:  3.719840036607088e-09\n",
      " loss:  3.502852588527362e-09\n",
      " loss:  3.298520705084613e-09\n",
      " loss:  3.1061584127020786e-09\n",
      " loss:  2.9250327669285484e-09\n",
      " loss:  2.7544863730527053e-09\n",
      " loss:  2.593879140934909e-09\n",
      " loss:  2.442678076795938e-09\n",
      " loss:  2.3003099168748793e-09\n",
      " loss:  2.166306132988878e-09\n",
      " loss:  2.0400378835461956e-09\n",
      " loss:  1.921163330513065e-09\n",
      " loss:  1.8092266848314057e-09\n",
      " loss:  1.7038273734901965e-09\n",
      " loss:  1.6045614267129245e-09\n",
      " loss:  1.5111229668139905e-09\n",
      " loss:  1.4231079397615534e-09\n",
      " loss:  1.3402427268079322e-09\n",
      " loss:  1.2621928756715638e-09\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-6 -*-\n",
    "import numpy as np\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机输入和输出数据\n",
    "x = np.random.randn(N,D_in) # 根据给定维度生成[0,1)之间的数据，包含0，不包含1\n",
    "y = np.random.randn(N,D_out)\n",
    "\n",
    "# 随机初始化权重\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 =np.random.randn(H,D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "h = x.dot(w1)\n",
    "for t in range(500):\n",
    "    # 前向传播：计算预测值y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # 计算和打印损失loss\n",
    "    loss = np.square(y_pred-y).sum()\n",
    "    print(' loss: ',loss)\n",
    "\n",
    "    # 反向传播，计算w1和w2对loss的梯度\n",
    "    grad_y_pred = 2.0 *(y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T) \n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0]=0\n",
    "    grad_w1 =x.T.dot(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 PyTorch：张量\n",
    "* 张量（Tensor）：PyTorch的tensor在概念上与numpy的array相同： tensor是一个n维数组，PyTorch提供了许多函数用于操作这些张量。任何希望使用NumPy执行的计算也可以使用PyTorch的tensor来完成，可以认为它们是科学计算的通用工具。\n",
    "* PyTorch可以利用GPU加速其数值计算。要在GPU上运行Tensor,在构造张量使用device参数把tensor建立在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss:  35308600.0\n",
      " loss:  27167694.0\n",
      " loss:  20703268.0\n",
      " loss:  14675038.0\n",
      " loss:  9730498.0\n",
      " loss:  6247756.0\n",
      " loss:  4060622.75\n",
      " loss:  2750066.5\n",
      " loss:  1965486.125\n",
      " loss:  1478761.25\n",
      " loss:  1159810.25\n",
      " loss:  937825.125\n",
      " loss:  774978.75\n",
      " loss:  650740.0\n",
      " loss:  552898.625\n",
      " loss:  474015.0\n",
      " loss:  409391.875\n",
      " loss:  355701.5\n",
      " loss:  310709.0\n",
      " loss:  272673.3125\n",
      " loss:  240322.578125\n",
      " loss:  212622.890625\n",
      " loss:  188774.90625\n",
      " loss:  168168.78125\n",
      " loss:  150270.90625\n",
      " loss:  134658.34375\n",
      " loss:  120993.765625\n",
      " loss:  109008.203125\n",
      " loss:  98448.890625\n",
      " loss:  89122.2734375\n",
      " loss:  80854.953125\n",
      " loss:  73499.640625\n",
      " loss:  66940.25\n",
      " loss:  61076.7890625\n",
      " loss:  55820.7109375\n",
      " loss:  51100.36328125\n",
      " loss:  46851.02734375\n",
      " loss:  43018.6328125\n",
      " loss:  39555.796875\n",
      " loss:  36417.99609375\n",
      " loss:  33571.3984375\n",
      " loss:  30986.482421875\n",
      " loss:  28632.05859375\n",
      " loss:  26484.01171875\n",
      " loss:  24522.521484375\n",
      " loss:  22727.759765625\n",
      " loss:  21082.62109375\n",
      " loss:  19572.70703125\n",
      " loss:  18185.68359375\n",
      " loss:  16909.64453125\n",
      " loss:  15734.482421875\n",
      " loss:  14651.0888671875\n",
      " loss:  13651.3388671875\n",
      " loss:  12728.1953125\n",
      " loss:  11874.5107421875\n",
      " loss:  11084.318359375\n",
      " loss:  10352.35546875\n",
      " loss:  9673.763671875\n",
      " loss:  9044.578125\n",
      " loss:  8460.43359375\n",
      " loss:  7917.68701171875\n",
      " loss:  7412.880859375\n",
      " loss:  6943.07421875\n",
      " loss:  6504.5166015625\n",
      " loss:  6096.1796875\n",
      " loss:  5715.564453125\n",
      " loss:  5360.7333984375\n",
      " loss:  5029.5263671875\n",
      " loss:  4720.37109375\n",
      " loss:  4431.650390625\n",
      " loss:  4161.96044921875\n",
      " loss:  3909.8935546875\n",
      " loss:  3674.17578125\n",
      " loss:  3453.584716796875\n",
      " loss:  3247.080078125\n",
      " loss:  3053.6962890625\n",
      " loss:  2872.61767578125\n",
      " loss:  2702.9873046875\n",
      " loss:  2543.951171875\n",
      " loss:  2394.85400390625\n",
      " loss:  2254.988037109375\n",
      " loss:  2123.75439453125\n",
      " loss:  2000.5595703125\n",
      " loss:  1884.8870849609375\n",
      " loss:  1776.2119140625\n",
      " loss:  1674.1361083984375\n",
      " loss:  1578.210205078125\n",
      " loss:  1488.020751953125\n",
      " loss:  1403.222900390625\n",
      " loss:  1323.552978515625\n",
      " loss:  1248.6087646484375\n",
      " loss:  1178.081787109375\n",
      " loss:  1111.7178955078125\n",
      " loss:  1049.241455078125\n",
      " loss:  990.40771484375\n",
      " loss:  935.0050659179688\n",
      " loss:  882.8270263671875\n",
      " loss:  833.662109375\n",
      " loss:  787.3273315429688\n",
      " loss:  743.6669921875\n",
      " loss:  702.51220703125\n",
      " loss:  663.7212524414062\n",
      " loss:  627.1349487304688\n",
      " loss:  592.635986328125\n",
      " loss:  560.09375\n",
      " loss:  529.395751953125\n",
      " loss:  500.43206787109375\n",
      " loss:  473.099365234375\n",
      " loss:  447.3056335449219\n",
      " loss:  422.9560546875\n",
      " loss:  399.96795654296875\n",
      " loss:  378.26611328125\n",
      " loss:  357.79437255859375\n",
      " loss:  338.48944091796875\n",
      " loss:  320.2498474121094\n",
      " loss:  303.0228271484375\n",
      " loss:  286.749755859375\n",
      " loss:  271.36724853515625\n",
      " loss:  256.83587646484375\n",
      " loss:  243.10205078125\n",
      " loss:  230.11981201171875\n",
      " loss:  217.84918212890625\n",
      " loss:  206.24618530273438\n",
      " loss:  195.28021240234375\n",
      " loss:  184.9070587158203\n",
      " loss:  175.0980987548828\n",
      " loss:  165.82049560546875\n",
      " loss:  157.0474395751953\n",
      " loss:  148.7465057373047\n",
      " loss:  140.89390563964844\n",
      " loss:  133.46646118164062\n",
      " loss:  126.43770599365234\n",
      " loss:  119.78652954101562\n",
      " loss:  113.49154663085938\n",
      " loss:  107.53526306152344\n",
      " loss:  101.89811706542969\n",
      " loss:  96.55941772460938\n",
      " loss:  91.50843811035156\n",
      " loss:  86.72552490234375\n",
      " loss:  82.19842529296875\n",
      " loss:  77.9133529663086\n",
      " loss:  73.85485076904297\n",
      " loss:  70.01005554199219\n",
      " loss:  66.3698501586914\n",
      " loss:  62.921382904052734\n",
      " loss:  59.656097412109375\n",
      " loss:  56.56271743774414\n",
      " loss:  53.63263702392578\n",
      " loss:  50.85556411743164\n",
      " loss:  48.22683334350586\n",
      " loss:  45.73524475097656\n",
      " loss:  43.37445068359375\n",
      " loss:  41.138187408447266\n",
      " loss:  39.01809310913086\n",
      " loss:  37.009342193603516\n",
      " loss:  35.10506057739258\n",
      " loss:  33.30029296875\n",
      " loss:  31.591279983520508\n",
      " loss:  29.970481872558594\n",
      " loss:  28.43474578857422\n",
      " loss:  26.97766876220703\n",
      " loss:  25.596694946289062\n",
      " loss:  24.287384033203125\n",
      " loss:  23.04546356201172\n",
      " loss:  21.86872100830078\n",
      " loss:  20.752864837646484\n",
      " loss:  19.694547653198242\n",
      " loss:  18.69062042236328\n",
      " loss:  17.739147186279297\n",
      " loss:  16.836339950561523\n",
      " loss:  15.980009078979492\n",
      " loss:  15.168132781982422\n",
      " loss:  14.397915840148926\n",
      " loss:  13.667448043823242\n",
      " loss:  12.974611282348633\n",
      " loss:  12.316841125488281\n",
      " loss:  11.693094253540039\n",
      " loss:  11.101354598999023\n",
      " loss:  10.540166854858398\n",
      " loss:  10.007442474365234\n",
      " loss:  9.502559661865234\n",
      " loss:  9.022360801696777\n",
      " loss:  8.567386627197266\n",
      " loss:  8.135433197021484\n",
      " loss:  7.725410461425781\n",
      " loss:  7.336725234985352\n",
      " loss:  6.9675445556640625\n",
      " loss:  6.617421627044678\n",
      " loss:  6.28488826751709\n",
      " loss:  5.968934059143066\n",
      " loss:  5.669492244720459\n",
      " loss:  5.385095596313477\n",
      " loss:  5.114965915679932\n",
      " loss:  4.858806610107422\n",
      " loss:  4.6153459548950195\n",
      " loss:  4.384451866149902\n",
      " loss:  4.165311336517334\n",
      " loss:  3.9569010734558105\n",
      " loss:  3.759223461151123\n",
      " loss:  3.5713131427764893\n",
      " loss:  3.3931193351745605\n",
      " loss:  3.223771810531616\n",
      " loss:  3.063100576400757\n",
      " loss:  2.910518169403076\n",
      " loss:  2.7654128074645996\n",
      " loss:  2.6277358531951904\n",
      " loss:  2.497042179107666\n",
      " loss:  2.3729467391967773\n",
      " loss:  2.25484037399292\n",
      " loss:  2.142711877822876\n",
      " loss:  2.036370038986206\n",
      " loss:  1.9353314638137817\n",
      " loss:  1.839408040046692\n",
      " loss:  1.7481215000152588\n",
      " loss:  1.6614997386932373\n",
      " loss:  1.5792800188064575\n",
      " loss:  1.5011065006256104\n",
      " loss:  1.4267410039901733\n",
      " loss:  1.3561007976531982\n",
      " loss:  1.2890615463256836\n",
      " loss:  1.2253949642181396\n",
      " loss:  1.1648317575454712\n",
      " loss:  1.1073172092437744\n",
      " loss:  1.0526591539382935\n",
      " loss:  1.000688910484314\n",
      " loss:  0.9513911008834839\n",
      " loss:  0.9045349359512329\n",
      " loss:  0.8599389791488647\n",
      " loss:  0.8175370693206787\n",
      " loss:  0.7773057818412781\n",
      " loss:  0.7390291690826416\n",
      " loss:  0.7026657462120056\n",
      " loss:  0.6681725978851318\n",
      " loss:  0.6353600025177002\n",
      " loss:  0.6041327714920044\n",
      " loss:  0.5744704604148865\n",
      " loss:  0.5462464094161987\n",
      " loss:  0.5194118618965149\n",
      " loss:  0.4939652681350708\n",
      " loss:  0.46982136368751526\n",
      " loss:  0.4467586278915405\n",
      " loss:  0.42487776279449463\n",
      " loss:  0.40410029888153076\n",
      " loss:  0.38427990674972534\n",
      " loss:  0.36545658111572266\n",
      " loss:  0.34756141901016235\n",
      " loss:  0.33054471015930176\n",
      " loss:  0.31439805030822754\n",
      " loss:  0.29906147718429565\n",
      " loss:  0.28444740176200867\n",
      " loss:  0.27057474851608276\n",
      " loss:  0.25739872455596924\n",
      " loss:  0.2448432743549347\n",
      " loss:  0.2328302264213562\n",
      " loss:  0.22158047556877136\n",
      " loss:  0.2107582688331604\n",
      " loss:  0.20046842098236084\n",
      " loss:  0.19070546329021454\n",
      " loss:  0.18141785264015198\n",
      " loss:  0.17256319522857666\n",
      " loss:  0.1642095446586609\n",
      " loss:  0.15623529255390167\n",
      " loss:  0.14864477515220642\n",
      " loss:  0.1414193958044052\n",
      " loss:  0.13452690839767456\n",
      " loss:  0.1280076801776886\n",
      " loss:  0.12178590893745422\n",
      " loss:  0.11588313430547714\n",
      " loss:  0.1102621778845787\n",
      " loss:  0.10492284595966339\n",
      " loss:  0.09982225298881531\n",
      " loss:  0.09498769789934158\n",
      " loss:  0.09040365368127823\n",
      " loss:  0.08603580296039581\n",
      " loss:  0.0818563848733902\n",
      " loss:  0.07790578156709671\n",
      " loss:  0.074114590883255\n",
      " loss:  0.07054059952497482\n",
      " loss:  0.06712264567613602\n",
      " loss:  0.06386451423168182\n",
      " loss:  0.060796335339546204\n",
      " loss:  0.057857755571603775\n",
      " loss:  0.05506386235356331\n",
      " loss:  0.052426520735025406\n",
      " loss:  0.04989420995116234\n",
      " loss:  0.047498125582933426\n",
      " loss:  0.04521704465150833\n",
      " loss:  0.04303143545985222\n",
      " loss:  0.04096236452460289\n",
      " loss:  0.03898908942937851\n",
      " loss:  0.03711792826652527\n",
      " loss:  0.03533661365509033\n",
      " loss:  0.03366035223007202\n",
      " loss:  0.03204119950532913\n",
      " loss:  0.03050815686583519\n",
      " loss:  0.029039688408374786\n",
      " loss:  0.027654588222503662\n",
      " loss:  0.026321128010749817\n",
      " loss:  0.025058366358280182\n",
      " loss:  0.023863237351179123\n",
      " loss:  0.022729096934199333\n",
      " loss:  0.02164960466325283\n",
      " loss:  0.0206209234893322\n",
      " loss:  0.019643083214759827\n",
      " loss:  0.018703820183873177\n",
      " loss:  0.01781677082180977\n",
      " loss:  0.016973821446299553\n",
      " loss:  0.0161628108471632\n",
      " loss:  0.015399194322526455\n",
      " loss:  0.014671962708234787\n",
      " loss:  0.013978373259305954\n",
      " loss:  0.013319112360477448\n",
      " loss:  0.012691210955381393\n",
      " loss:  0.012084925547242165\n",
      " loss:  0.011516762897372246\n",
      " loss:  0.010979600250720978\n",
      " loss:  0.010463087819516659\n",
      " loss:  0.009977687150239944\n",
      " loss:  0.009513730183243752\n",
      " loss:  0.009070120751857758\n",
      " loss:  0.008654769510030746\n",
      " loss:  0.008252071216702461\n",
      " loss:  0.007869470864534378\n",
      " loss:  0.007509787101298571\n",
      " loss:  0.007164623588323593\n",
      " loss:  0.006834081374108791\n",
      " loss:  0.006526791490614414\n",
      " loss:  0.006227494217455387\n",
      " loss:  0.005943667143583298\n",
      " loss:  0.00567952124401927\n",
      " loss:  0.005421740934252739\n",
      " loss:  0.005177424289286137\n",
      " loss:  0.004947439301759005\n",
      " loss:  0.004722640849649906\n",
      " loss:  0.00451458478346467\n",
      " loss:  0.004315635189414024\n",
      " loss:  0.004120588302612305\n",
      " loss:  0.003940798807889223\n",
      " loss:  0.0037663672119379044\n",
      " loss:  0.003606678918004036\n",
      " loss:  0.0034523927606642246\n",
      " loss:  0.0033011240884661674\n",
      " loss:  0.003159171901643276\n",
      " loss:  0.003025222569704056\n",
      " loss:  0.0028960448689758778\n",
      " loss:  0.002773677697405219\n",
      " loss:  0.002655807649716735\n",
      " loss:  0.002543281763792038\n",
      " loss:  0.002436478855088353\n",
      " loss:  0.002336592646315694\n",
      " loss:  0.002241954207420349\n",
      " loss:  0.0021480440627783537\n",
      " loss:  0.002060233149677515\n",
      " loss:  0.0019743184093385935\n",
      " loss:  0.0018943343311548233\n",
      " loss:  0.0018187700770795345\n",
      " loss:  0.0017483714036643505\n",
      " loss:  0.001677969004958868\n",
      " loss:  0.001614251872524619\n",
      " loss:  0.0015514391707256436\n",
      " loss:  0.0014919138047844172\n",
      " loss:  0.001432409044355154\n",
      " loss:  0.0013797758147120476\n",
      " loss:  0.0013255885569378734\n",
      " loss:  0.0012753388145938516\n",
      " loss:  0.0012293485924601555\n",
      " loss:  0.001183163607493043\n",
      " loss:  0.00113997096195817\n",
      " loss:  0.0010994126787409186\n",
      " loss:  0.0010603787377476692\n",
      " loss:  0.0010226985905319452\n",
      " loss:  0.0009849498746916652\n",
      " loss:  0.0009501646272838116\n",
      " loss:  0.0009166622767224908\n",
      " loss:  0.0008848117431625724\n",
      " loss:  0.0008549907943233848\n",
      " loss:  0.0008240590104833245\n",
      " loss:  0.0007968532736413181\n",
      " loss:  0.0007702467264607549\n",
      " loss:  0.0007433200953528285\n",
      " loss:  0.0007185175782069564\n",
      " loss:  0.000695363967679441\n",
      " loss:  0.0006715836352668703\n",
      " loss:  0.0006500877789221704\n",
      " loss:  0.0006292200414463878\n",
      " loss:  0.0006093116826377809\n",
      " loss:  0.0005889065214432776\n",
      " loss:  0.000571477459743619\n",
      " loss:  0.0005539865233004093\n",
      " loss:  0.0005361916846595705\n",
      " loss:  0.0005196572747081518\n",
      " loss:  0.0005040038377046585\n",
      " loss:  0.0004887060495093465\n",
      " loss:  0.000474272936116904\n",
      " loss:  0.00046004512114450336\n",
      " loss:  0.00044551765313372016\n",
      " loss:  0.0004328358336351812\n",
      " loss:  0.0004203718854114413\n",
      " loss:  0.00040813919622451067\n",
      " loss:  0.0003963830240536481\n",
      " loss:  0.00038568186573684216\n",
      " loss:  0.00037486464134417474\n",
      " loss:  0.0003647826670203358\n",
      " loss:  0.0003543489146977663\n",
      " loss:  0.00034408422652632\n",
      " loss:  0.0003352765052113682\n",
      " loss:  0.00032610533526167274\n",
      " loss:  0.00031752680661156774\n",
      " loss:  0.0003091200487688184\n",
      " loss:  0.00030077097471803427\n",
      " loss:  0.00029281259048730135\n",
      " loss:  0.0002856537466868758\n",
      " loss:  0.0002782766823656857\n",
      " loss:  0.00027112936368212104\n",
      " loss:  0.00026413617888465524\n",
      " loss:  0.0002573594101704657\n",
      " loss:  0.0002505365409888327\n",
      " loss:  0.0002446640864945948\n",
      " loss:  0.00023859746579546481\n",
      " loss:  0.00023280557070393115\n",
      " loss:  0.00022681494010612369\n",
      " loss:  0.00022092898143455386\n",
      " loss:  0.0002157356939278543\n",
      " loss:  0.00021065390319563448\n",
      " loss:  0.00020597814000211656\n",
      " loss:  0.0002011873002629727\n",
      " loss:  0.000196081557078287\n",
      " loss:  0.0001920460199471563\n",
      " loss:  0.00018715643091127276\n",
      " loss:  0.00018303058459423482\n",
      " loss:  0.000178895250428468\n",
      " loss:  0.00017472472973167896\n",
      " loss:  0.0001711889635771513\n",
      " loss:  0.00016735013923607767\n",
      " loss:  0.00016366009367629886\n",
      " loss:  0.0001600377436261624\n",
      " loss:  0.00015651699504815042\n",
      " loss:  0.00015358251403085887\n",
      " loss:  0.00015004465240053833\n",
      " loss:  0.00014706479851156473\n",
      " loss:  0.00014408788410946727\n",
      " loss:  0.00014092391938902438\n",
      " loss:  0.00013785235933028162\n",
      " loss:  0.0001351390965282917\n",
      " loss:  0.0001329359511146322\n",
      " loss:  0.00013007631059736013\n",
      " loss:  0.0001277134142583236\n",
      " loss:  0.00012489617802202702\n",
      " loss:  0.00012185695231892169\n",
      " loss:  0.00011997585534118116\n",
      " loss:  0.00011737915338017046\n",
      " loss:  0.00011535286466823891\n",
      " loss:  0.00011326752428431064\n",
      " loss:  0.00011089710460510105\n",
      " loss:  0.00010877892054850236\n",
      " loss:  0.00010703399311751127\n",
      " loss:  0.00010499865311430767\n",
      " loss:  0.00010303797898814082\n",
      " loss:  0.00010112316522281617\n",
      " loss:  9.895418770611286e-05\n",
      " loss:  9.702333773020655e-05\n",
      " loss:  9.543282794766128e-05\n",
      " loss:  9.36905198614113e-05\n",
      " loss:  9.180725464830175e-05\n",
      " loss:  9.012549708131701e-05\n",
      " loss:  8.874476043274626e-05\n",
      " loss:  8.743243961362168e-05\n",
      " loss:  8.577719563618302e-05\n",
      " loss:  8.43279849505052e-05\n",
      " loss:  8.29750788398087e-05\n",
      " loss:  8.197215356631204e-05\n",
      " loss:  8.044957212405279e-05\n",
      " loss:  7.918681512819603e-05\n",
      " loss:  7.804095366736874e-05\n",
      " loss:  7.660479604965076e-05\n",
      " loss:  7.540106162196025e-05\n",
      " loss:  7.438145985361189e-05\n",
      " loss:  7.3042610893026e-05\n",
      " loss:  7.182650733739138e-05\n",
      " loss:  7.061182986944914e-05\n",
      " loss:  6.929227674845606e-05\n",
      " loss:  6.84078986523673e-05\n",
      " loss:  6.735362694598734e-05\n",
      " loss:  6.619695341214538e-05\n",
      " loss:  6.525982462335378e-05\n",
      " loss:  6.399861740646884e-05\n",
      " loss:  6.293068872764707e-05\n",
      " loss:  6.22538645984605e-05\n",
      " loss:  6.132024282123893e-05\n",
      " loss:  6.019673674018122e-05\n",
      " loss:  5.9423051425255835e-05\n",
      " loss:  5.8638775954023004e-05\n",
      " loss:  5.8215555327478796e-05\n",
      " loss:  5.696693551726639e-05\n",
      " loss:  5.619590956484899e-05\n",
      " loss:  5.5346266890410334e-05\n",
      " loss:  5.481211337610148e-05\n",
      " loss:  5.3888739785179496e-05\n",
      " loss:  5.331570719135925e-05\n",
      " loss:  5.2554954891093075e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机输入和输出数据\n",
    "x = torch.randn(N, D_in,device=device,dtype=dtype)  # 根据给定维度生成[0,1)之间的数据，包含0，不包含1\n",
    "y = torch.randn(N, D_out,device=device,dtype=dtype)\n",
    "\n",
    "# 随机初始化权重\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out,device=device,dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    # 前向传播：计算预测值y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # 计算和打印损失loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(' loss: ', loss)\n",
    "\n",
    "    # 反向传播，计算w1和w2对loss的梯度\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.T)\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.mm(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.自动求导\n",
    "#### 3.1 pytorch：张量和自动求导\n",
    "* 当使用autograd时，网络前向传播将定义一个计算图；图中的节点是tensor，边是函数， 这些函数是输出tensor到输入tensor的映射。这张计算图使得在网络中反向传播时梯度的计算十分简单\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  29578572.0\n",
      "loss:  26053104.0\n",
      "loss:  28070774.0\n",
      "loss:  30917336.0\n",
      "loss:  30529200.0\n",
      "loss:  24546144.0\n",
      "loss:  15835134.0\n",
      "loss:  8505678.0\n",
      "loss:  4295978.0\n",
      "loss:  2280633.0\n",
      "loss:  1379345.875\n",
      "loss:  953496.625\n",
      "loss:  729118.375\n",
      "loss:  591094.25\n",
      "loss:  495694.125\n",
      "loss:  422987.25\n",
      "loss:  365112.6875\n",
      "loss:  317228.375\n",
      "loss:  277338.8125\n",
      "loss:  243485.3125\n",
      "loss:  214713.03125\n",
      "loss:  190003.34375\n",
      "loss:  168774.5625\n",
      "loss:  150385.8125\n",
      "loss:  134441.703125\n",
      "loss:  120516.8984375\n",
      "loss:  108351.15625\n",
      "loss:  97665.8828125\n",
      "loss:  88256.8359375\n",
      "loss:  79947.5703125\n",
      "loss:  72585.921875\n",
      "loss:  66053.2578125\n",
      "loss:  60243.390625\n",
      "loss:  55053.9609375\n",
      "loss:  50412.796875\n",
      "loss:  46253.71875\n",
      "loss:  42519.94140625\n",
      "loss:  39159.0078125\n",
      "loss:  36129.8515625\n",
      "loss:  33395.0859375\n",
      "loss:  30923.005859375\n",
      "loss:  28684.19140625\n",
      "loss:  26653.17578125\n",
      "loss:  24807.1640625\n",
      "loss:  23126.5\n",
      "loss:  21595.76171875\n",
      "loss:  20198.6328125\n",
      "loss:  18920.84765625\n",
      "loss:  17752.080078125\n",
      "loss:  16682.591796875\n",
      "loss:  15701.466796875\n",
      "loss:  14800.884765625\n",
      "loss:  13972.46875\n",
      "loss:  13210.0029296875\n",
      "loss:  12507.630859375\n",
      "loss:  11860.0546875\n",
      "loss:  11262.2998046875\n",
      "loss:  10710.17578125\n",
      "loss:  10199.67578125\n",
      "loss:  9726.8408203125\n",
      "loss:  9289.7138671875\n",
      "loss:  8884.765625\n",
      "loss:  8508.78515625\n",
      "loss:  8159.310546875\n",
      "loss:  7834.40087890625\n",
      "loss:  7532.65625\n",
      "loss:  7250.92626953125\n",
      "loss:  6988.5078125\n",
      "loss:  6743.13330078125\n",
      "loss:  6513.8896484375\n",
      "loss:  6299.4736328125\n",
      "loss:  6098.5546875\n",
      "loss:  5910.20556640625\n",
      "loss:  5733.3310546875\n",
      "loss:  5567.36474609375\n",
      "loss:  5411.1298828125\n",
      "loss:  5264.0341796875\n",
      "loss:  5125.4296875\n",
      "loss:  4994.82080078125\n",
      "loss:  4871.2294921875\n",
      "loss:  4754.6201171875\n",
      "loss:  4644.1455078125\n",
      "loss:  4539.51171875\n",
      "loss:  4440.04296875\n",
      "loss:  4345.64453125\n",
      "loss:  4255.72509765625\n",
      "loss:  4170.458984375\n",
      "loss:  4088.98388671875\n",
      "loss:  4011.5009765625\n",
      "loss:  3937.14990234375\n",
      "loss:  3866.5078125\n",
      "loss:  3798.66650390625\n",
      "loss:  3733.679931640625\n",
      "loss:  3671.4833984375\n",
      "loss:  3611.609375\n",
      "loss:  3554.271484375\n",
      "loss:  3498.83935546875\n",
      "loss:  3445.44775390625\n",
      "loss:  3394.106201171875\n",
      "loss:  3344.289306640625\n",
      "loss:  3296.265625\n",
      "loss:  3249.84228515625\n",
      "loss:  3204.7431640625\n",
      "loss:  3161.112548828125\n",
      "loss:  3118.80419921875\n",
      "loss:  3077.60986328125\n",
      "loss:  3037.647705078125\n",
      "loss:  2998.787109375\n",
      "loss:  2960.83544921875\n",
      "loss:  2923.922607421875\n",
      "loss:  2887.83837890625\n",
      "loss:  2852.720703125\n",
      "loss:  2818.2353515625\n",
      "loss:  2784.66650390625\n",
      "loss:  2751.814453125\n",
      "loss:  2719.6728515625\n",
      "loss:  2688.03564453125\n",
      "loss:  2657.213623046875\n",
      "loss:  2626.8798828125\n",
      "loss:  2597.221923828125\n",
      "loss:  2568.079833984375\n",
      "loss:  2539.4423828125\n",
      "loss:  2511.427001953125\n",
      "loss:  2483.71826171875\n",
      "loss:  2456.58056640625\n",
      "loss:  2428.3525390625\n",
      "loss:  2400.96044921875\n",
      "loss:  2374.14208984375\n",
      "loss:  2347.906005859375\n",
      "loss:  2322.1669921875\n",
      "loss:  2296.839111328125\n",
      "loss:  2271.94677734375\n",
      "loss:  2247.522216796875\n",
      "loss:  2223.352783203125\n",
      "loss:  2199.713134765625\n",
      "loss:  2176.36669921875\n",
      "loss:  2153.388671875\n",
      "loss:  2130.786376953125\n",
      "loss:  2108.41943359375\n",
      "loss:  2086.474853515625\n",
      "loss:  2064.800537109375\n",
      "loss:  2042.83056640625\n",
      "loss:  2021.5279541015625\n",
      "loss:  2000.2379150390625\n",
      "loss:  1979.5595703125\n",
      "loss:  1958.92724609375\n",
      "loss:  1938.663330078125\n",
      "loss:  1918.6859130859375\n",
      "loss:  1898.906982421875\n",
      "loss:  1879.474609375\n",
      "loss:  1860.2158203125\n",
      "loss:  1841.3153076171875\n",
      "loss:  1822.5782470703125\n",
      "loss:  1804.15478515625\n",
      "loss:  1785.9521484375\n",
      "loss:  1767.912841796875\n",
      "loss:  1750.526123046875\n",
      "loss:  1733.39892578125\n",
      "loss:  1716.52734375\n",
      "loss:  1699.816162109375\n",
      "loss:  1683.235107421875\n",
      "loss:  1666.9786376953125\n",
      "loss:  1650.7650146484375\n",
      "loss:  1634.8587646484375\n",
      "loss:  1618.94677734375\n",
      "loss:  1603.4227294921875\n",
      "loss:  1587.9525146484375\n",
      "loss:  1572.379638671875\n",
      "loss:  1557.253173828125\n",
      "loss:  1542.132568359375\n",
      "loss:  1527.356201171875\n",
      "loss:  1512.582763671875\n",
      "loss:  1498.1876220703125\n",
      "loss:  1483.777587890625\n",
      "loss:  1469.73876953125\n",
      "loss:  1455.710693359375\n",
      "loss:  1442.0140380859375\n",
      "loss:  1428.352783203125\n",
      "loss:  1414.9130859375\n",
      "loss:  1401.637451171875\n",
      "loss:  1388.4285888671875\n",
      "loss:  1375.5194091796875\n",
      "loss:  1362.6473388671875\n",
      "loss:  1350.01708984375\n",
      "loss:  1337.4600830078125\n",
      "loss:  1325.173583984375\n",
      "loss:  1312.900390625\n",
      "loss:  1300.8677978515625\n",
      "loss:  1288.914306640625\n",
      "loss:  1277.1881103515625\n",
      "loss:  1265.4581298828125\n",
      "loss:  1254.0311279296875\n",
      "loss:  1242.6566162109375\n",
      "loss:  1231.1458740234375\n",
      "loss:  1219.9793701171875\n",
      "loss:  1208.7659912109375\n",
      "loss:  1197.8756103515625\n",
      "loss:  1186.9700927734375\n",
      "loss:  1176.3817138671875\n",
      "loss:  1165.7452392578125\n",
      "loss:  1155.490966796875\n",
      "loss:  1145.1181640625\n",
      "loss:  1135.083740234375\n",
      "loss:  1124.9884033203125\n",
      "loss:  1115.220703125\n",
      "loss:  1105.3951416015625\n",
      "loss:  1095.902587890625\n",
      "loss:  1086.2412109375\n",
      "loss:  1077.004150390625\n",
      "loss:  1067.64404296875\n",
      "loss:  1058.5836181640625\n",
      "loss:  1049.4876708984375\n",
      "loss:  1040.6500244140625\n",
      "loss:  1031.724853515625\n",
      "loss:  1023.098388671875\n",
      "loss:  1014.48486328125\n",
      "loss:  1006.0170288085938\n",
      "loss:  997.633056640625\n",
      "loss:  989.3214111328125\n",
      "loss:  981.1678466796875\n",
      "loss:  973.042236328125\n",
      "loss:  965.0838623046875\n",
      "loss:  957.159423828125\n",
      "loss:  949.4520263671875\n",
      "loss:  941.749267578125\n",
      "loss:  934.2102661132812\n",
      "loss:  926.632080078125\n",
      "loss:  919.26025390625\n",
      "loss:  911.9234619140625\n",
      "loss:  904.6986083984375\n",
      "loss:  897.539306640625\n",
      "loss:  890.4605712890625\n",
      "loss:  883.5112915039062\n",
      "loss:  876.7044067382812\n",
      "loss:  870.1091918945312\n",
      "loss:  863.481201171875\n",
      "loss:  856.9574584960938\n",
      "loss:  850.5034790039062\n",
      "loss:  844.0606689453125\n",
      "loss:  837.8031005859375\n",
      "loss:  831.3807373046875\n",
      "loss:  825.2139282226562\n",
      "loss:  819.0139770507812\n",
      "loss:  812.924072265625\n",
      "loss:  806.928955078125\n",
      "loss:  800.9107055664062\n",
      "loss:  794.9583740234375\n",
      "loss:  789.1695556640625\n",
      "loss:  783.3111572265625\n",
      "loss:  777.6133422851562\n",
      "loss:  771.966552734375\n",
      "loss:  766.307861328125\n",
      "loss:  760.7476196289062\n",
      "loss:  755.2034912109375\n",
      "loss:  749.7528076171875\n",
      "loss:  744.4383544921875\n",
      "loss:  739.1011962890625\n",
      "loss:  733.8975219726562\n",
      "loss:  728.7172241210938\n",
      "loss:  723.5433349609375\n",
      "loss:  718.5040893554688\n",
      "loss:  713.5110473632812\n",
      "loss:  708.5293579101562\n",
      "loss:  703.576171875\n",
      "loss:  698.7796630859375\n",
      "loss:  693.8864135742188\n",
      "loss:  689.213623046875\n",
      "loss:  684.4700927734375\n",
      "loss:  679.7752685546875\n",
      "loss:  675.1934814453125\n",
      "loss:  670.642333984375\n",
      "loss:  666.1414184570312\n",
      "loss:  661.6712646484375\n",
      "loss:  657.2196044921875\n",
      "loss:  652.916259765625\n",
      "loss:  648.5869140625\n",
      "loss:  644.3076782226562\n",
      "loss:  640.0543823242188\n",
      "loss:  635.9629516601562\n",
      "loss:  631.7757568359375\n",
      "loss:  627.694580078125\n",
      "loss:  623.6195678710938\n",
      "loss:  619.62109375\n",
      "loss:  615.713623046875\n",
      "loss:  611.7451171875\n",
      "loss:  607.8955078125\n",
      "loss:  604.0361938476562\n",
      "loss:  600.267578125\n",
      "loss:  596.539306640625\n",
      "loss:  592.2037353515625\n",
      "loss:  588.35595703125\n",
      "loss:  584.3882446289062\n",
      "loss:  580.6697998046875\n",
      "loss:  577.0074462890625\n",
      "loss:  573.3564453125\n",
      "loss:  569.819580078125\n",
      "loss:  566.34521484375\n",
      "loss:  562.8994140625\n",
      "loss:  559.5478515625\n",
      "loss:  556.2120361328125\n",
      "loss:  552.9234619140625\n",
      "loss:  549.66357421875\n",
      "loss:  546.485595703125\n",
      "loss:  543.3186645507812\n",
      "loss:  540.0615234375\n",
      "loss:  537.0167846679688\n",
      "loss:  533.8589477539062\n",
      "loss:  530.8961791992188\n",
      "loss:  527.8033447265625\n",
      "loss:  524.876953125\n",
      "loss:  521.8977661132812\n",
      "loss:  519.037109375\n",
      "loss:  516.096923828125\n",
      "loss:  513.2808227539062\n",
      "loss:  510.44683837890625\n",
      "loss:  507.6730651855469\n",
      "loss:  504.89825439453125\n",
      "loss:  502.1601257324219\n",
      "loss:  499.4964599609375\n",
      "loss:  496.77142333984375\n",
      "loss:  494.1512756347656\n",
      "loss:  491.513427734375\n",
      "loss:  488.94012451171875\n",
      "loss:  486.328369140625\n",
      "loss:  483.82818603515625\n",
      "loss:  481.2750549316406\n",
      "loss:  478.78863525390625\n",
      "loss:  476.32183837890625\n",
      "loss:  473.89227294921875\n",
      "loss:  471.4359130859375\n",
      "loss:  469.0682067871094\n",
      "loss:  466.6935729980469\n",
      "loss:  464.30902099609375\n",
      "loss:  462.00054931640625\n",
      "loss:  459.6863098144531\n",
      "loss:  457.38153076171875\n",
      "loss:  455.11773681640625\n",
      "loss:  452.89190673828125\n",
      "loss:  450.5930480957031\n",
      "loss:  448.45404052734375\n",
      "loss:  446.241943359375\n",
      "loss:  444.08282470703125\n",
      "loss:  441.94512939453125\n",
      "loss:  439.8423767089844\n",
      "loss:  437.7100524902344\n",
      "loss:  435.65899658203125\n",
      "loss:  433.5664978027344\n",
      "loss:  431.54486083984375\n",
      "loss:  429.499755859375\n",
      "loss:  427.5018005371094\n",
      "loss:  425.49786376953125\n",
      "loss:  423.55322265625\n",
      "loss:  421.5640563964844\n",
      "loss:  419.67144775390625\n",
      "loss:  417.69073486328125\n",
      "loss:  415.8382568359375\n",
      "loss:  413.9136657714844\n",
      "loss:  412.07818603515625\n",
      "loss:  410.19879150390625\n",
      "loss:  408.38726806640625\n",
      "loss:  406.5308837890625\n",
      "loss:  404.766357421875\n",
      "loss:  402.95904541015625\n",
      "loss:  401.1916809082031\n",
      "loss:  399.4118957519531\n",
      "loss:  397.6998291015625\n",
      "loss:  395.9261474609375\n",
      "loss:  394.255126953125\n",
      "loss:  392.51885986328125\n",
      "loss:  390.8738708496094\n",
      "loss:  389.17425537109375\n",
      "loss:  387.56915283203125\n",
      "loss:  385.89849853515625\n",
      "loss:  384.33013916015625\n",
      "loss:  382.6784973144531\n",
      "loss:  381.12359619140625\n",
      "loss:  379.5123291015625\n",
      "loss:  377.97174072265625\n",
      "loss:  376.39892578125\n",
      "loss:  374.8675842285156\n",
      "loss:  373.33050537109375\n",
      "loss:  371.80810546875\n",
      "loss:  370.3337097167969\n",
      "loss:  368.8123779296875\n",
      "loss:  367.3753662109375\n",
      "loss:  365.8553466796875\n",
      "loss:  364.43792724609375\n",
      "loss:  362.9801025390625\n",
      "loss:  361.5520935058594\n",
      "loss:  360.11077880859375\n",
      "loss:  358.72308349609375\n",
      "loss:  357.30914306640625\n",
      "loss:  355.92877197265625\n",
      "loss:  354.54266357421875\n",
      "loss:  353.1813049316406\n",
      "loss:  351.80291748046875\n",
      "loss:  350.47698974609375\n",
      "loss:  349.13385009765625\n",
      "loss:  347.828857421875\n",
      "loss:  346.4908447265625\n",
      "loss:  345.2178955078125\n",
      "loss:  343.89886474609375\n",
      "loss:  342.64849853515625\n",
      "loss:  341.3590087890625\n",
      "loss:  340.1069030761719\n",
      "loss:  338.85675048828125\n",
      "loss:  337.6128845214844\n",
      "loss:  336.3817138671875\n",
      "loss:  335.168701171875\n",
      "loss:  333.9380187988281\n",
      "loss:  332.76226806640625\n",
      "loss:  331.5504150390625\n",
      "loss:  330.3433532714844\n",
      "loss:  329.177734375\n",
      "loss:  327.98907470703125\n",
      "loss:  326.8665771484375\n",
      "loss:  325.67889404296875\n",
      "loss:  324.576416015625\n",
      "loss:  323.447021484375\n",
      "loss:  322.3078918457031\n",
      "loss:  320.9607238769531\n",
      "loss:  319.9815368652344\n",
      "loss:  318.700927734375\n",
      "loss:  317.7480773925781\n",
      "loss:  316.54351806640625\n",
      "loss:  315.60772705078125\n",
      "loss:  314.4306335449219\n",
      "loss:  313.4989929199219\n",
      "loss:  312.37591552734375\n",
      "loss:  311.4169616699219\n",
      "loss:  310.3291931152344\n",
      "loss:  309.3807373046875\n",
      "loss:  308.340087890625\n",
      "loss:  307.3675231933594\n",
      "loss:  306.352783203125\n",
      "loss:  305.3914794921875\n",
      "loss:  304.4105529785156\n",
      "loss:  303.42041015625\n",
      "loss:  302.4766540527344\n",
      "loss:  301.49298095703125\n",
      "loss:  300.5784912109375\n",
      "loss:  299.597412109375\n",
      "loss:  298.6891784667969\n",
      "loss:  297.72528076171875\n",
      "loss:  296.80224609375\n",
      "loss:  295.9050598144531\n",
      "loss:  294.95849609375\n",
      "loss:  294.10064697265625\n",
      "loss:  293.1551513671875\n",
      "loss:  292.056396484375\n",
      "loss:  291.3670654296875\n",
      "loss:  290.2830810546875\n",
      "loss:  289.57037353515625\n",
      "loss:  288.54876708984375\n",
      "loss:  287.78216552734375\n",
      "loss:  286.80487060546875\n",
      "loss:  286.02008056640625\n",
      "loss:  284.8522033691406\n",
      "loss:  284.0680847167969\n",
      "loss:  282.97265625\n",
      "loss:  282.2059020996094\n",
      "loss:  281.173095703125\n",
      "loss:  280.41876220703125\n",
      "loss:  279.4431457519531\n",
      "loss:  278.697265625\n",
      "loss:  277.7669372558594\n",
      "loss:  277.0126647949219\n",
      "loss:  276.12103271484375\n",
      "loss:  275.382080078125\n",
      "loss:  274.50604248046875\n",
      "loss:  273.7796325683594\n",
      "loss:  272.921875\n",
      "loss:  272.20477294921875\n",
      "loss:  271.2358703613281\n",
      "loss:  270.59930419921875\n",
      "loss:  269.6788330078125\n",
      "loss:  269.0474853515625\n",
      "loss:  268.15478515625\n",
      "loss:  267.5157470703125\n",
      "loss:  266.643798828125\n",
      "loss:  266.02374267578125\n",
      "loss:  265.1490478515625\n",
      "loss:  264.3721008300781\n",
      "loss:  263.542724609375\n",
      "loss:  262.82061767578125\n",
      "loss:  262.0194091796875\n",
      "loss:  261.3058776855469\n",
      "loss:  260.5665283203125\n",
      "loss:  259.8624572753906\n",
      "loss:  259.0758056640625\n",
      "loss:  258.35308837890625\n",
      "loss:  257.5919189453125\n",
      "loss:  256.89569091796875\n",
      "loss:  256.15594482421875\n",
      "loss:  255.473876953125\n",
      "loss:  254.75372314453125\n",
      "loss:  254.08522033691406\n",
      "loss:  253.38436889648438\n",
      "loss:  252.71978759765625\n",
      "loss:  252.0430450439453\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import torch\n",
    "\n",
    "dytpe = torch.float\n",
    "device = torch.device('cpu')\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机Tensors以保持输入和输出。\n",
    "# 设置requires_grad = False表示我们不需要计算渐变\n",
    "# 在向后传球期间对于这些Tensors。\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# 为权重创建随机Tensors。\n",
    "# 设置requires_grad = True表示我们想要计算渐变\n",
    "# 在向后传播期间更新这些张量\n",
    "w1 = torch.randn(D_in,H,device=device,dtype=dtype,requires_grad=True)\n",
    "w2 = torch.randn(H,D_out,device=device,dtype=dtype,requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for y in range(500):\n",
    "    # 前向传播：使用tensors上的操作计算预测值y;\n",
    "    # 由于w1和w2有requires_grad=True，涉及这些张量的操作将让PyTorch构建计算图，\n",
    "    # 从而允许自动计算梯度。由于我们不再手工实现反向传播，所以不需要保留中间值的引用\n",
    "    y_pred=x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # 使用Tensors上的操作计算和打印loss。\n",
    "    # loss是一个形状为()的张量\n",
    "    # loss.item() 得到这个张量对应的python数值\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print('loss: ',loss.item())\n",
    "\n",
    "    # 使用autograd计算反向传播。这个调用将计算loss对所有requires_grad=True的tensor的梯度。\n",
    "    # 这次调用后，w1.grad和w2.grad将分别是loss对w1和w2的梯度张量。、\n",
    "    loss.backward()\n",
    "\n",
    "    # 使用梯度下降更新权重。对于这一步，我们只想对w1和w2的值进行原地改变；不想为更新阶段构建计算图，\n",
    "    # 所以我们使用torch.no_grad()上下文管理器防止PyTorch为更新构建计算图\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # 反向传播后手动将梯度设置为零\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 定义新的自动求导函数\n",
    "* 通过定义 torch.autograd.Funtion 的子类并实现forward和backword函数，来定义自己的自定义求导运算\n",
    "* 通过构造一个实例并像调用函数一样，传入包含输入数据的tensor调用它，这样来使用新的自动求导运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32178116.0\n",
      "1 29365356.0\n",
      "2 29153736.0\n",
      "3 26920474.0\n",
      "4 21427748.0\n",
      "5 14226256.0\n",
      "6 8347204.0\n",
      "7 4662173.0\n",
      "8 2729230.5\n",
      "9 1753281.125\n",
      "10 1247396.375\n",
      "11 959790.25\n",
      "12 777484.75\n",
      "13 649732.5\n",
      "14 553106.375\n",
      "15 476347.6875\n",
      "16 413638.3125\n",
      "17 361513.0625\n",
      "18 317490.6875\n",
      "19 279996.90625\n",
      "20 247828.0625\n",
      "21 220116.9375\n",
      "22 196101.375\n",
      "23 175227.75\n",
      "24 157005.765625\n",
      "25 141013.5625\n",
      "26 126928.328125\n",
      "27 114527.8125\n",
      "28 103566.28125\n",
      "29 93835.8046875\n",
      "30 85176.890625\n",
      "31 77449.8515625\n",
      "32 70539.1171875\n",
      "33 64341.9296875\n",
      "34 58774.078125\n",
      "35 53778.32421875\n",
      "36 49279.65234375\n",
      "37 45220.859375\n",
      "38 41545.015625\n",
      "39 38209.21484375\n",
      "40 35181.046875\n",
      "41 32425.634765625\n",
      "42 29913.568359375\n",
      "43 27619.47265625\n",
      "44 25523.32421875\n",
      "45 23606.27734375\n",
      "46 21851.36328125\n",
      "47 20245.56640625\n",
      "48 18772.080078125\n",
      "49 17417.99609375\n",
      "50 16173.21484375\n",
      "51 15027.234375\n",
      "52 13970.3603515625\n",
      "53 12996.138671875\n",
      "54 12096.154296875\n",
      "55 11265.509765625\n",
      "56 10498.349609375\n",
      "57 9787.921875\n",
      "58 9130.2890625\n",
      "59 8521.087890625\n",
      "60 7956.10546875\n",
      "61 7431.94482421875\n",
      "62 6944.89599609375\n",
      "63 6492.31005859375\n",
      "64 6071.3798828125\n",
      "65 5679.7861328125\n",
      "66 5315.5\n",
      "67 4976.5751953125\n",
      "68 4660.482421875\n",
      "69 4365.9453125\n",
      "70 4091.27197265625\n",
      "71 3835.250244140625\n",
      "72 3596.255859375\n",
      "73 3373.082275390625\n",
      "74 3164.69091796875\n",
      "75 2970.0283203125\n",
      "76 2788.10595703125\n",
      "77 2618.0498046875\n",
      "78 2459.11962890625\n",
      "79 2310.27685546875\n",
      "80 2171.097900390625\n",
      "81 2040.716064453125\n",
      "82 1918.544921875\n",
      "83 1804.059326171875\n",
      "84 1696.793701171875\n",
      "85 1596.19091796875\n",
      "86 1501.91796875\n",
      "87 1413.5260009765625\n",
      "88 1330.5394287109375\n",
      "89 1252.6815185546875\n",
      "90 1179.5504150390625\n",
      "91 1110.896240234375\n",
      "92 1046.406005859375\n",
      "93 985.7855224609375\n",
      "94 928.8804931640625\n",
      "95 875.4065551757812\n",
      "96 825.099853515625\n",
      "97 777.8678588867188\n",
      "98 733.456298828125\n",
      "99 691.6722412109375\n",
      "100 652.3922119140625\n",
      "101 615.4262084960938\n",
      "102 580.610107421875\n",
      "103 547.8543701171875\n",
      "104 517.018310546875\n",
      "105 487.98577880859375\n",
      "106 460.6398620605469\n",
      "107 434.8983459472656\n",
      "108 410.6200256347656\n",
      "109 387.7396240234375\n",
      "110 366.18499755859375\n",
      "111 345.8676452636719\n",
      "112 326.72833251953125\n",
      "113 308.69024658203125\n",
      "114 291.6669921875\n",
      "115 275.6092529296875\n",
      "116 260.4642639160156\n",
      "117 246.1719970703125\n",
      "118 232.69566345214844\n",
      "119 219.97457885742188\n",
      "120 207.97549438476562\n",
      "121 196.65206909179688\n",
      "122 185.95724487304688\n",
      "123 175.86927795410156\n",
      "124 166.33609008789062\n",
      "125 157.33203125\n",
      "126 148.8302001953125\n",
      "127 140.80328369140625\n",
      "128 133.2195281982422\n",
      "129 126.05655670166016\n",
      "130 119.28993225097656\n",
      "131 112.89308166503906\n",
      "132 106.85400390625\n",
      "133 101.1407470703125\n",
      "134 95.74259185791016\n",
      "135 90.63960266113281\n",
      "136 85.8144760131836\n",
      "137 81.25354766845703\n",
      "138 76.93998718261719\n",
      "139 72.8590087890625\n",
      "140 69.00105285644531\n",
      "141 65.35643768310547\n",
      "142 61.90711975097656\n",
      "143 58.641910552978516\n",
      "144 55.55534362792969\n",
      "145 52.63373565673828\n",
      "146 49.86929702758789\n",
      "147 47.25225830078125\n",
      "148 44.77702331542969\n",
      "149 42.43409729003906\n",
      "150 40.216087341308594\n",
      "151 38.116676330566406\n",
      "152 36.132080078125\n",
      "153 34.25178909301758\n",
      "154 32.472434997558594\n",
      "155 30.786643981933594\n",
      "156 29.18976593017578\n",
      "157 27.676746368408203\n",
      "158 26.243608474731445\n",
      "159 24.886850357055664\n",
      "160 23.60174560546875\n",
      "161 22.38425064086914\n",
      "162 21.232709884643555\n",
      "163 20.13943099975586\n",
      "164 19.103961944580078\n",
      "165 18.12253761291504\n",
      "166 17.192977905273438\n",
      "167 16.31220817565918\n",
      "168 15.477014541625977\n",
      "169 14.685030937194824\n",
      "170 13.93526840209961\n",
      "171 13.223926544189453\n",
      "172 12.549381256103516\n",
      "173 11.910858154296875\n",
      "174 11.304267883300781\n",
      "175 10.72987174987793\n",
      "176 10.18453311920166\n",
      "177 9.668213844299316\n",
      "178 9.178108215332031\n",
      "179 8.713293075561523\n",
      "180 8.27252197265625\n",
      "181 7.854094505310059\n",
      "182 7.457771301269531\n",
      "183 7.0815887451171875\n",
      "184 6.724533557891846\n",
      "185 6.385796546936035\n",
      "186 6.06492280960083\n",
      "187 5.760090351104736\n",
      "188 5.470629692077637\n",
      "189 5.196150779724121\n",
      "190 4.935352325439453\n",
      "191 4.688215255737305\n",
      "192 4.453317165374756\n",
      "193 4.230837345123291\n",
      "194 4.019783973693848\n",
      "195 3.819146156311035\n",
      "196 3.628477096557617\n",
      "197 3.4477717876434326\n",
      "198 3.276116132736206\n",
      "199 3.1130547523498535\n",
      "200 2.958325147628784\n",
      "201 2.8113884925842285\n",
      "202 2.6717476844787598\n",
      "203 2.5392229557037354\n",
      "204 2.413351535797119\n",
      "205 2.293945550918579\n",
      "206 2.180516481399536\n",
      "207 2.0728414058685303\n",
      "208 1.9704604148864746\n",
      "209 1.873098611831665\n",
      "210 1.7806326150894165\n",
      "211 1.693013072013855\n",
      "212 1.6095913648605347\n",
      "213 1.530335545539856\n",
      "214 1.4551903009414673\n",
      "215 1.3836634159088135\n",
      "216 1.3158472776412964\n",
      "217 1.251274824142456\n",
      "218 1.1898640394210815\n",
      "219 1.1315529346466064\n",
      "220 1.076140284538269\n",
      "221 1.0234456062316895\n",
      "222 0.9735483527183533\n",
      "223 0.9259198904037476\n",
      "224 0.8807545304298401\n",
      "225 0.8377333879470825\n",
      "226 0.796951949596405\n",
      "227 0.7580530643463135\n",
      "228 0.7211709022521973\n",
      "229 0.686119556427002\n",
      "230 0.6527960300445557\n",
      "231 0.6210918426513672\n",
      "232 0.5909258127212524\n",
      "233 0.56220942735672\n",
      "234 0.5349494218826294\n",
      "235 0.5090787410736084\n",
      "236 0.48441383242607117\n",
      "237 0.4609726667404175\n",
      "238 0.4386991560459137\n",
      "239 0.4174685478210449\n",
      "240 0.397294282913208\n",
      "241 0.3781929612159729\n",
      "242 0.35997527837753296\n",
      "243 0.34258708357810974\n",
      "244 0.3260694146156311\n",
      "245 0.31038379669189453\n",
      "246 0.2954404950141907\n",
      "247 0.281218945980072\n",
      "248 0.267713725566864\n",
      "249 0.25484922528266907\n",
      "250 0.24262458086013794\n",
      "251 0.2310394048690796\n",
      "252 0.21992456912994385\n",
      "253 0.20941130816936493\n",
      "254 0.19939181208610535\n",
      "255 0.18983381986618042\n",
      "256 0.18078584969043732\n",
      "257 0.17211909592151642\n",
      "258 0.16390419006347656\n",
      "259 0.1561042219400406\n",
      "260 0.14863023161888123\n",
      "261 0.14157012104988098\n",
      "262 0.13483178615570068\n",
      "263 0.12841388583183289\n",
      "264 0.12231747806072235\n",
      "265 0.11650007963180542\n",
      "266 0.1109682098031044\n",
      "267 0.10568185895681381\n",
      "268 0.10067182779312134\n",
      "269 0.09588515758514404\n",
      "270 0.09134130924940109\n",
      "271 0.08700302243232727\n",
      "272 0.0828787162899971\n",
      "273 0.078963503241539\n",
      "274 0.07524271309375763\n",
      "275 0.071680448949337\n",
      "276 0.0683058500289917\n",
      "277 0.06509441137313843\n",
      "278 0.06202104687690735\n",
      "279 0.059102050960063934\n",
      "280 0.0563090480864048\n",
      "281 0.053661394864320755\n",
      "282 0.05112007260322571\n",
      "283 0.04871875047683716\n",
      "284 0.04643717408180237\n",
      "285 0.044254839420318604\n",
      "286 0.04217632859945297\n",
      "287 0.04019191116094589\n",
      "288 0.03831347078084946\n",
      "289 0.036518394947052\n",
      "290 0.034806765615940094\n",
      "291 0.03317716717720032\n",
      "292 0.03162489831447601\n",
      "293 0.03015286475419998\n",
      "294 0.028748102486133575\n",
      "295 0.02741033211350441\n",
      "296 0.026141542941331863\n",
      "297 0.024931764230132103\n",
      "298 0.0237714983522892\n",
      "299 0.022677574306726456\n",
      "300 0.021632827818393707\n",
      "301 0.020625527948141098\n",
      "302 0.019668204709887505\n",
      "303 0.018757781013846397\n",
      "304 0.01789860427379608\n",
      "305 0.01707816682755947\n",
      "306 0.01629638671875\n",
      "307 0.015542077831923962\n",
      "308 0.014837316237390041\n",
      "309 0.014152733609080315\n",
      "310 0.01350213959813118\n",
      "311 0.012881776317954063\n",
      "312 0.012294803746044636\n",
      "313 0.01173754408955574\n",
      "314 0.01120276004076004\n",
      "315 0.010692711919546127\n",
      "316 0.010216817259788513\n",
      "317 0.00975615344941616\n",
      "318 0.00932219997048378\n",
      "319 0.008903132751584053\n",
      "320 0.008508509956300259\n",
      "321 0.008124354295432568\n",
      "322 0.007761343382298946\n",
      "323 0.007411131169646978\n",
      "324 0.007080519571900368\n",
      "325 0.006769420113414526\n",
      "326 0.006471293047070503\n",
      "327 0.006183602847158909\n",
      "328 0.005915272980928421\n",
      "329 0.005653410218656063\n",
      "330 0.005410332232713699\n",
      "331 0.005173001438379288\n",
      "332 0.004951181821525097\n",
      "333 0.004734615329653025\n",
      "334 0.004529089201241732\n",
      "335 0.004332591779530048\n",
      "336 0.0041501084342598915\n",
      "337 0.003973569720983505\n",
      "338 0.0038076620548963547\n",
      "339 0.0036453946959227324\n",
      "340 0.003491968149319291\n",
      "341 0.003346455516293645\n",
      "342 0.0032049124129116535\n",
      "343 0.00307287834584713\n",
      "344 0.0029450219590216875\n",
      "345 0.0028245376888662577\n",
      "346 0.002711743814870715\n",
      "347 0.002599503844976425\n",
      "348 0.0024938215501606464\n",
      "349 0.0023950806353241205\n",
      "350 0.0022979197092354298\n",
      "351 0.0022073511499911547\n",
      "352 0.0021200943738222122\n",
      "353 0.0020377025939524174\n",
      "354 0.0019571580924093723\n",
      "355 0.0018813754431903362\n",
      "356 0.0018094810657203197\n",
      "357 0.001740786014124751\n",
      "358 0.0016731871291995049\n",
      "359 0.0016094906022772193\n",
      "360 0.0015477398410439491\n",
      "361 0.001490462920628488\n",
      "362 0.0014347906690090895\n",
      "363 0.0013823944609612226\n",
      "364 0.00133152911439538\n",
      "365 0.0012814842630177736\n",
      "366 0.001236546435393393\n",
      "367 0.0011896328069269657\n",
      "368 0.0011477735824882984\n",
      "369 0.0011075516231358051\n",
      "370 0.0010678106918931007\n",
      "371 0.0010305712930858135\n",
      "372 0.0009941791649907827\n",
      "373 0.0009579587494954467\n",
      "374 0.0009253930766135454\n",
      "375 0.0008923684363253415\n",
      "376 0.0008624597103334963\n",
      "377 0.0008330214768648148\n",
      "378 0.0008059163810685277\n",
      "379 0.0007789973169565201\n",
      "380 0.0007518513011746109\n",
      "381 0.0007277130498550832\n",
      "382 0.0007042930810712278\n",
      "383 0.0006815800443291664\n",
      "384 0.0006603485671803355\n",
      "385 0.0006377040408551693\n",
      "386 0.0006179358460940421\n",
      "387 0.0005975464591756463\n",
      "388 0.0005802454543299973\n",
      "389 0.0005616804119199514\n",
      "390 0.0005452806362882257\n",
      "391 0.0005285184597596526\n",
      "392 0.0005121571011841297\n",
      "393 0.0004976295167580247\n",
      "394 0.0004823626368306577\n",
      "395 0.0004679123230744153\n",
      "396 0.0004540710069704801\n",
      "397 0.00044056083424948156\n",
      "398 0.00042834519990719855\n",
      "399 0.0004151261236984283\n",
      "400 0.00040329337934963405\n",
      "401 0.0003924382326658815\n",
      "402 0.0003813452203758061\n",
      "403 0.0003701933892443776\n",
      "404 0.00036020297557115555\n",
      "405 0.0003506665234453976\n",
      "406 0.00034143077209591866\n",
      "407 0.0003314903296995908\n",
      "408 0.0003229523135814816\n",
      "409 0.0003136570448987186\n",
      "410 0.0003058436850551516\n",
      "411 0.00029785308288410306\n",
      "412 0.00028961081989109516\n",
      "413 0.000282563385553658\n",
      "414 0.00027419166872277856\n",
      "415 0.0002676011063158512\n",
      "416 0.0002600637380965054\n",
      "417 0.00025306473253294826\n",
      "418 0.00024668851983733475\n",
      "419 0.00024085160112008452\n",
      "420 0.00023511912149842829\n",
      "421 0.00022954129963181913\n",
      "422 0.00022415106650441885\n",
      "423 0.00021838530665263534\n",
      "424 0.00021393319184426218\n",
      "425 0.0002087675966322422\n",
      "426 0.00020383266382850707\n",
      "427 0.00019830440578516573\n",
      "428 0.00019416710711084306\n",
      "429 0.00018954083498101681\n",
      "430 0.00018538256699685007\n",
      "431 0.00018095114501193166\n",
      "432 0.0001767856301739812\n",
      "433 0.0001727891358314082\n",
      "434 0.00016900492482818663\n",
      "435 0.00016517718904651701\n",
      "436 0.00016135718033183366\n",
      "437 0.00015753664774820209\n",
      "438 0.00015434986562468112\n",
      "439 0.0001510644651716575\n",
      "440 0.00014750607078894973\n",
      "441 0.00014471696340478957\n",
      "442 0.00014108489267528057\n",
      "443 0.00013829156523570418\n",
      "444 0.00013538930215872824\n",
      "445 0.0001326541241724044\n",
      "446 0.00012996222358196974\n",
      "447 0.00012738132500089705\n",
      "448 0.00012473121751099825\n",
      "449 0.00012224340753164142\n",
      "450 0.00011960734991589561\n",
      "451 0.00011763160000555217\n",
      "452 0.00011497993546072394\n",
      "453 0.00011252924741711468\n",
      "454 0.00011028155859094113\n",
      "455 0.00010784164624055848\n",
      "456 0.00010578001820249483\n",
      "457 0.00010426145308883861\n",
      "458 0.00010197958908975124\n",
      "459 0.00010004958312492818\n",
      "460 9.81686171144247e-05\n",
      "461 9.63279017014429e-05\n",
      "462 9.441803558729589e-05\n",
      "463 9.269207657780498e-05\n",
      "464 9.114616841543466e-05\n",
      "465 8.942966815084219e-05\n",
      "466 8.771572902332991e-05\n",
      "467 8.608168718637899e-05\n",
      "468 8.466326107736677e-05\n",
      "469 8.32121295388788e-05\n",
      "470 8.183364843716845e-05\n",
      "471 8.021237590583041e-05\n",
      "472 7.897037721704692e-05\n",
      "473 7.740665751043707e-05\n",
      "474 7.646385347470641e-05\n",
      "475 7.492148142773658e-05\n",
      "476 7.393130363197997e-05\n",
      "477 7.252772047650069e-05\n",
      "478 7.133858889574185e-05\n",
      "479 7.005581574048847e-05\n",
      "480 6.889790529385209e-05\n",
      "481 6.76053314236924e-05\n",
      "482 6.635929457843304e-05\n",
      "483 6.520392344100401e-05\n",
      "484 6.41481310594827e-05\n",
      "485 6.316414510365576e-05\n",
      "486 6.221490912139416e-05\n",
      "487 6.135721923783422e-05\n",
      "488 6.032646706444211e-05\n",
      "489 5.936516390647739e-05\n",
      "490 5.8576217270456254e-05\n",
      "491 5.738942127209157e-05\n",
      "492 5.6572323956061155e-05\n",
      "493 5.570694702328183e-05\n",
      "494 5.478332604980096e-05\n",
      "495 5.4004798585083336e-05\n",
      "496 5.326724931364879e-05\n",
      "497 5.225732456892729e-05\n",
      "498 5.143913585925475e-05\n",
      "499 5.097499524708837e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class MyRelu(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    我们可以通过建立torch.autograd的子类来实现我们自定义的autograd函数，\n",
    "    并完成张量的正向和反向传播。\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx,x):\n",
    "        \"\"\"\n",
    "        在正向传播中，我们接收到一个上下文对象和一个包含输入的张量；\n",
    "        我们必须返回一个包含输出的张量，\n",
    "        并且我们可以使用上下文对象来缓存对象，以便在反向传播中使用。\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(x)\n",
    "        return x.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        在反向传播中，我们接收到上下文对象和一个张量，\n",
    "        其包含了相对于正向传播过程中产生的输出的损失的梯度。\n",
    "        我们可以从上下文对象中检索缓存的数据，\n",
    "        并且必须计算并返回与正向传播的输入相关的损失的梯度。\n",
    "        \"\"\"\n",
    "        x, =ctx.saved_tensors\n",
    "        grad_x = grad_output.clone()\n",
    "        grad_x[x<0] = 0\n",
    "        return grad_x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# N是批大小； D_in 是输入维度；\n",
    "# H 是隐藏层维度； D_out 是输出维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 产生输入和输出的随机张量\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out,device=device)\n",
    "\n",
    "# 产生随机权重的张量\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 正向传播：使用张量上的操作来计算输出值y；\n",
    "    # 我们通过调用 MyReLU.apply 函数来使用自定义的ReLU\n",
    "    y_pred = MyRelu.apply(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # 计算并输出loss\n",
    "    # 计算并输出loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 使用autograd计算反向传播过程。\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 用梯度下降更新权重\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # 在反向传播之后手动清零梯度\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 TensorFlow:静态图\n",
    "* TensorFlow的计算图是静态的，而PyTorch使用动态的计算图\n",
    "* 在TensorFlow中，我们定义计算图一次，然后重复执行这个相同的图，可能会提供不同的输入数据。而在PyTorch中，每一个前向通道定义一个新的计算图。\n",
    "* 静态图的好处在于你可以预先对图进行优化\n",
    "* 静态图和动态图的一个区别是控制流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 首先我们建立计算图（computational graph）\n",
    "\n",
    "# N是批大小；D是输入维度；\n",
    "# H是隐藏层维度；D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 为输入和目标数据创建placeholder；\n",
    "# 当执行计算图时，他们将会被真实的数据填充\n",
    "x = tf.placeholder(tf.float32, shape=(None, D_in))\n",
    "y = tf.placeholder(tf.float32, shape=(None, D_out))\n",
    "\n",
    "# 为权重创建Variable并用随机数据初始化\n",
    "# TensorFlow的Variable在执行计算图时不会改变\n",
    "w1 = tf.Variable(tf.random_normal((D_in, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D_out)))\n",
    "\n",
    "# 前向传播：使用TensorFlow的张量运算计算预测值y。\n",
    "# 注意这段代码实际上不执行任何数值运算；\n",
    "# 它只是建立了我们稍后将执行的计算图。\n",
    "h = tf.matmul(x, w1)\n",
    "h_relu = tf.maximum(h, tf.zeros(1))\n",
    "y_pred = tf.matmul(h_relu, w2)\n",
    "\n",
    "# 使用TensorFlow的张量运算损失（loss）\n",
    "loss = tf.reduce_sum((y - y_pred)**2.0)\n",
    "\n",
    "# 计算loss对于w1和w2的导数\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "# 使用梯度下降更新权重。为了实际更新权重，我们需要在执行计算图时计算new_w1和new_w2。\n",
    "# 注意，在TensorFlow中，更新权重值的行为是计算图的一部分;\n",
    "# 但在PyTorch中，这发生在计算图形之外。\n",
    "learning_rate = 1e-6\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "# 现在我们搭建好了计算图，所以我们开始一个TensorFlow的会话（session）来实际执行计算图。\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 运行一次计算图来初始化Variable w1和w2\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 创建numpy数组来存储输入x和目标y的实际数据\n",
    "    x_value = np.random.randn(N, D_in)\n",
    "    y_value = np.random.randn(N, D_out)\n",
    "\n",
    "    for _ in range(500):\n",
    "        # 多次运行计算图。每次执行时，我们都用feed_dict参数，\n",
    "        # 将x_value绑定到x，将y_value绑定到y，\n",
    "        # 每次执行图形时我们都要计算损失、new_w1和new_w2；\n",
    "        # 这些张量的值以numpy数组的形式返回。\n",
    "        loss_value, _, _ = sess.run([loss, new_w1, new_w2],\n",
    "                                    feed_dict={\n",
    "                                        x: x_value,\n",
    "                                        y: y_value\n",
    "                                    })\n",
    "        print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. nn模块\n",
    "#### nn\n",
    "* 对于大规模的网络，autograd太过于底层\n",
    "* 在构建神经网络时，我们经常考虑将计算安排成层，其中一些具有可学习的参数，它们将在学习过程中进行优化。\n",
    "    * TensorFlow里，有类似Keras，TensorFlow-Slim和TFLearn这种封装了底层计算图的高度抽象的接口，这使得构建网络十分方便\n",
    "    * 在PyTorch中，包nn完成了同样的功能\n",
    "* nn包中定义一组大致等价于层的模块\n",
    "* 一个模块接受输入的tesnor，计算输出的tensor，而且 还保存了一些内部状态比如需要学习的tensor的参数等\n",
    "* nn包中也定义了一组损失函数（loss functions），用来训练神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 643.3059692382812\n",
      "1 593.9111938476562\n",
      "2 551.6248168945312\n",
      "3 515.1810302734375\n",
      "4 482.95147705078125\n",
      "5 454.0457763671875\n",
      "6 427.9096984863281\n",
      "7 404.23895263671875\n",
      "8 382.6553039550781\n",
      "9 362.75750732421875\n",
      "10 344.1855163574219\n",
      "11 326.85174560546875\n",
      "12 310.49853515625\n",
      "13 295.1378479003906\n",
      "14 280.6236572265625\n",
      "15 266.810546875\n",
      "16 253.710205078125\n",
      "17 241.20240783691406\n",
      "18 229.20852661132812\n",
      "19 217.7664794921875\n",
      "20 206.79656982421875\n",
      "21 196.27996826171875\n",
      "22 186.27685546875\n",
      "23 176.71080017089844\n",
      "24 167.5751190185547\n",
      "25 158.85414123535156\n",
      "26 150.54006958007812\n",
      "27 142.61607360839844\n",
      "28 135.05540466308594\n",
      "29 127.86219024658203\n",
      "30 121.02880096435547\n",
      "31 114.5145492553711\n",
      "32 108.32154846191406\n",
      "33 102.43174743652344\n",
      "34 96.8521499633789\n",
      "35 91.55996704101562\n",
      "36 86.54949951171875\n",
      "37 81.79074096679688\n",
      "38 77.29391479492188\n",
      "39 73.03854370117188\n",
      "40 69.015380859375\n",
      "41 65.21244812011719\n",
      "42 61.61769104003906\n",
      "43 58.230072021484375\n",
      "44 55.036949157714844\n",
      "45 52.022029876708984\n",
      "46 49.17859649658203\n",
      "47 46.502052307128906\n",
      "48 43.97301483154297\n",
      "49 41.59125900268555\n",
      "50 39.338233947753906\n",
      "51 37.218833923339844\n",
      "52 35.224510192871094\n",
      "53 33.348472595214844\n",
      "54 31.577449798583984\n",
      "55 29.90727996826172\n",
      "56 28.33405113220215\n",
      "57 26.852481842041016\n",
      "58 25.455677032470703\n",
      "59 24.13918113708496\n",
      "60 22.896188735961914\n",
      "61 21.722993850708008\n",
      "62 20.61457633972168\n",
      "63 19.57094383239746\n",
      "64 18.583078384399414\n",
      "65 17.65036964416504\n",
      "66 16.76935386657715\n",
      "67 15.935646057128906\n",
      "68 15.148701667785645\n",
      "69 14.404195785522461\n",
      "70 13.699553489685059\n",
      "71 13.032472610473633\n",
      "72 12.400798797607422\n",
      "73 11.802796363830566\n",
      "74 11.23612117767334\n",
      "75 10.699131965637207\n",
      "76 10.190841674804688\n",
      "77 9.707771301269531\n",
      "78 9.249706268310547\n",
      "79 8.815824508666992\n",
      "80 8.4042387008667\n",
      "81 8.012420654296875\n",
      "82 7.640545845031738\n",
      "83 7.288415431976318\n",
      "84 6.953319549560547\n",
      "85 6.634847164154053\n",
      "86 6.331991672515869\n",
      "87 6.044025897979736\n",
      "88 5.770010471343994\n",
      "89 5.509222507476807\n",
      "90 5.260968208312988\n",
      "91 5.0247063636779785\n",
      "92 4.79978609085083\n",
      "93 4.586090087890625\n",
      "94 4.382813930511475\n",
      "95 4.189162731170654\n",
      "96 4.004782199859619\n",
      "97 3.829061508178711\n",
      "98 3.661652088165283\n",
      "99 3.5019423961639404\n",
      "100 3.349867820739746\n",
      "101 3.204716205596924\n",
      "102 3.0663464069366455\n",
      "103 2.9343855381011963\n",
      "104 2.808549404144287\n",
      "105 2.688429594039917\n",
      "106 2.5738158226013184\n",
      "107 2.464448928833008\n",
      "108 2.360208749771118\n",
      "109 2.260843515396118\n",
      "110 2.1659553050994873\n",
      "111 2.0753426551818848\n",
      "112 1.988653302192688\n",
      "113 1.9058334827423096\n",
      "114 1.8268671035766602\n",
      "115 1.7513399124145508\n",
      "116 1.6791596412658691\n",
      "117 1.610061526298523\n",
      "118 1.5441486835479736\n",
      "119 1.481183409690857\n",
      "120 1.4209637641906738\n",
      "121 1.3633673191070557\n",
      "122 1.308258056640625\n",
      "123 1.2555463314056396\n",
      "124 1.2050684690475464\n",
      "125 1.1568669080734253\n",
      "126 1.110718846321106\n",
      "127 1.0665615797042847\n",
      "128 1.0242810249328613\n",
      "129 0.9837448000907898\n",
      "130 0.9449552297592163\n",
      "131 0.9077972173690796\n",
      "132 0.872177243232727\n",
      "133 0.8380435109138489\n",
      "134 0.8053473830223083\n",
      "135 0.7740174531936646\n",
      "136 0.7439925074577332\n",
      "137 0.715186595916748\n",
      "138 0.6875802874565125\n",
      "139 0.6611186265945435\n",
      "140 0.6357269287109375\n",
      "141 0.6113749742507935\n",
      "142 0.5880386233329773\n",
      "143 0.5656582713127136\n",
      "144 0.5441732406616211\n",
      "145 0.5235503911972046\n",
      "146 0.503777801990509\n",
      "147 0.4848073422908783\n",
      "148 0.4665752351284027\n",
      "149 0.449065625667572\n",
      "150 0.432248055934906\n",
      "151 0.41610467433929443\n",
      "152 0.4005897641181946\n",
      "153 0.3856993615627289\n",
      "154 0.3714113235473633\n",
      "155 0.3576667606830597\n",
      "156 0.34446293115615845\n",
      "157 0.3317825496196747\n",
      "158 0.31958237290382385\n",
      "159 0.3078545331954956\n",
      "160 0.29659271240234375\n",
      "161 0.28574708104133606\n",
      "162 0.2753264904022217\n",
      "163 0.265307754278183\n",
      "164 0.255674809217453\n",
      "165 0.24640975892543793\n",
      "166 0.23750261962413788\n",
      "167 0.22892674803733826\n",
      "168 0.2206876575946808\n",
      "169 0.21275238692760468\n",
      "170 0.20512062311172485\n",
      "171 0.1977693736553192\n",
      "172 0.19069577753543854\n",
      "173 0.18389301002025604\n",
      "174 0.17734317481517792\n",
      "175 0.17103706300258636\n",
      "176 0.16496634483337402\n",
      "177 0.15911909937858582\n",
      "178 0.15349581837654114\n",
      "179 0.1480938196182251\n",
      "180 0.1428840607404709\n",
      "181 0.13786733150482178\n",
      "182 0.133037269115448\n",
      "183 0.12838594615459442\n",
      "184 0.1239105612039566\n",
      "185 0.11959384381771088\n",
      "186 0.11543142050504684\n",
      "187 0.11141161620616913\n",
      "188 0.10754281282424927\n",
      "189 0.10381295531988144\n",
      "190 0.10022062808275223\n",
      "191 0.09675709903240204\n",
      "192 0.09341654926538467\n",
      "193 0.09019829332828522\n",
      "194 0.0870959684252739\n",
      "195 0.08410432934761047\n",
      "196 0.08122004568576813\n",
      "197 0.07843874394893646\n",
      "198 0.07575982064008713\n",
      "199 0.07317643612623215\n",
      "200 0.07068473845720291\n",
      "201 0.0682787373661995\n",
      "202 0.06595809757709503\n",
      "203 0.06372121721506119\n",
      "204 0.061563316732645035\n",
      "205 0.0594804547727108\n",
      "206 0.05747148394584656\n",
      "207 0.05553550645709038\n",
      "208 0.053667742758989334\n",
      "209 0.051862142980098724\n",
      "210 0.050122372806072235\n",
      "211 0.04844377189874649\n",
      "212 0.046823445707559586\n",
      "213 0.04525888338685036\n",
      "214 0.04374837875366211\n",
      "215 0.04229119420051575\n",
      "216 0.04088451340794563\n",
      "217 0.03952541574835777\n",
      "218 0.03821505233645439\n",
      "219 0.03694883733987808\n",
      "220 0.03572603315114975\n",
      "221 0.03454635664820671\n",
      "222 0.03340672329068184\n",
      "223 0.032305266708135605\n",
      "224 0.03124173916876316\n",
      "225 0.030214747413992882\n",
      "226 0.029222363606095314\n",
      "227 0.028264181688427925\n",
      "228 0.027338890358805656\n",
      "229 0.02644471637904644\n",
      "230 0.025580763816833496\n",
      "231 0.02474585548043251\n",
      "232 0.023939963430166245\n",
      "233 0.023161297664046288\n",
      "234 0.022408878430724144\n",
      "235 0.021681273356080055\n",
      "236 0.020978139713406563\n",
      "237 0.02029837667942047\n",
      "238 0.01964220032095909\n",
      "239 0.019007686525583267\n",
      "240 0.018394451588392258\n",
      "241 0.01780165359377861\n",
      "242 0.017229050397872925\n",
      "243 0.016674865037202835\n",
      "244 0.016139203682541847\n",
      "245 0.015621911734342575\n",
      "246 0.0151218818500638\n",
      "247 0.014638680964708328\n",
      "248 0.01417106855660677\n",
      "249 0.013718340545892715\n",
      "250 0.013281009159982204\n",
      "251 0.0128602534532547\n",
      "252 0.01245315931737423\n",
      "253 0.012059585191309452\n",
      "254 0.011678851209580898\n",
      "255 0.011310317553579807\n",
      "256 0.01095410156995058\n",
      "257 0.010609625838696957\n",
      "258 0.010276073589920998\n",
      "259 0.009953279979526997\n",
      "260 0.009641425684094429\n",
      "261 0.009339554235339165\n",
      "262 0.009047301486134529\n",
      "263 0.008764415979385376\n",
      "264 0.00849076360464096\n",
      "265 0.008226132951676846\n",
      "266 0.007969895377755165\n",
      "267 0.007722024340182543\n",
      "268 0.0074821156449615955\n",
      "269 0.0072498926892876625\n",
      "270 0.0070252250880002975\n",
      "271 0.006807524245232344\n",
      "272 0.006596803665161133\n",
      "273 0.006392814218997955\n",
      "274 0.006195419933646917\n",
      "275 0.0060042222030460835\n",
      "276 0.005819206591695547\n",
      "277 0.005640001967549324\n",
      "278 0.005466459784656763\n",
      "279 0.005298367701470852\n",
      "280 0.005135651212185621\n",
      "281 0.004978131037205458\n",
      "282 0.00482555478811264\n",
      "283 0.00467775110155344\n",
      "284 0.004534620326012373\n",
      "285 0.004396060016006231\n",
      "286 0.004261779598891735\n",
      "287 0.004131735302507877\n",
      "288 0.004005779512226582\n",
      "289 0.00388377346098423\n",
      "290 0.003765624016523361\n",
      "291 0.0036512059159576893\n",
      "292 0.003540273057296872\n",
      "293 0.0034328154288232327\n",
      "294 0.003328682156279683\n",
      "295 0.003227842506021261\n",
      "296 0.00313008320517838\n",
      "297 0.0030354249756783247\n",
      "298 0.002943754428997636\n",
      "299 0.002854940015822649\n",
      "300 0.0027688262052834034\n",
      "301 0.002685318235307932\n",
      "302 0.002604360692203045\n",
      "303 0.0025259670801460743\n",
      "304 0.00245001376606524\n",
      "305 0.0023763591889292\n",
      "306 0.00230499729514122\n",
      "307 0.0022358298301696777\n",
      "308 0.00216882792301476\n",
      "309 0.0021037645637989044\n",
      "310 0.0020407605916261673\n",
      "311 0.001979699358344078\n",
      "312 0.0019205274293199182\n",
      "313 0.0018631581915542483\n",
      "314 0.001807471620850265\n",
      "315 0.001753513002768159\n",
      "316 0.0017012589378282428\n",
      "317 0.0016505696112290025\n",
      "318 0.0016013773856684566\n",
      "319 0.0015537290601059794\n",
      "320 0.0015075282426550984\n",
      "321 0.0014628006611019373\n",
      "322 0.0014193487586453557\n",
      "323 0.0013772109523415565\n",
      "324 0.00133634137455374\n",
      "325 0.0012967460788786411\n",
      "326 0.0012583531206473708\n",
      "327 0.0012211172142997384\n",
      "328 0.0011849598959088326\n",
      "329 0.0011499178363010287\n",
      "330 0.001115929801017046\n",
      "331 0.0010829593520611525\n",
      "332 0.001051001832820475\n",
      "333 0.0010200124233961105\n",
      "334 0.000989965396001935\n",
      "335 0.0009607885731384158\n",
      "336 0.000932514201849699\n",
      "337 0.0009050786611624062\n",
      "338 0.0008784644305706024\n",
      "339 0.0008526400779373944\n",
      "340 0.0008275803993456066\n",
      "341 0.0008032991318032146\n",
      "342 0.000779752095695585\n",
      "343 0.0007569041335955262\n",
      "344 0.0007347115315496922\n",
      "345 0.0007131870952434838\n",
      "346 0.0006923109758645296\n",
      "347 0.0006720725796185434\n",
      "348 0.0006524088676087558\n",
      "349 0.0006333470810204744\n",
      "350 0.000614842982031405\n",
      "351 0.0005968943005427718\n",
      "352 0.0005794839235022664\n",
      "353 0.0005625730264000595\n",
      "354 0.0005461754626594484\n",
      "355 0.0005302579957060516\n",
      "356 0.0005148250493220985\n",
      "357 0.0004998621298000216\n",
      "358 0.0004853226419072598\n",
      "359 0.0004712176159955561\n",
      "360 0.00045753526501357555\n",
      "361 0.00044424604857340455\n",
      "362 0.0004313532845117152\n",
      "363 0.00041883974336087704\n",
      "364 0.00040667681605555117\n",
      "365 0.00039488659240305424\n",
      "366 0.0003834465751424432\n",
      "367 0.00037234387127682567\n",
      "368 0.00036157414433546364\n",
      "369 0.00035112263867631555\n",
      "370 0.0003409633063711226\n",
      "371 0.0003311069740448147\n",
      "372 0.0003215368778910488\n",
      "373 0.0003122479247394949\n",
      "374 0.0003032352833542973\n",
      "375 0.00029449001885950565\n",
      "376 0.0002860008680727333\n",
      "377 0.00027775997295975685\n",
      "378 0.00026975348009727895\n",
      "379 0.00026198296109214425\n",
      "380 0.0002544387534726411\n",
      "381 0.0002471152110956609\n",
      "382 0.00024001169367693365\n",
      "383 0.00023310785763897002\n",
      "384 0.0002264073264086619\n",
      "385 0.000219903580727987\n",
      "386 0.00021358896628953516\n",
      "387 0.00020745240908581764\n",
      "388 0.00020150902855675668\n",
      "389 0.00019572253222577274\n",
      "390 0.0001901064533740282\n",
      "391 0.00018465974426362664\n",
      "392 0.00017937179654836655\n",
      "393 0.00017423127428628504\n",
      "394 0.00016924520605243742\n",
      "395 0.00016439749742858112\n",
      "396 0.0001596957736182958\n",
      "397 0.00015513054677285254\n",
      "398 0.00015069538494572043\n",
      "399 0.00014639434812124819\n",
      "400 0.00014220652519725263\n",
      "401 0.0001381488546030596\n",
      "402 0.0001342058094451204\n",
      "403 0.00013037578901275992\n",
      "404 0.00012666334805544466\n",
      "405 0.0001230465859407559\n",
      "406 0.00011953957437071949\n",
      "407 0.00011613362585194409\n",
      "408 0.00011282869672868401\n",
      "409 0.00010961935186060145\n",
      "410 0.00010650022159097716\n",
      "411 0.00010347254283260554\n",
      "412 0.00010053357254946604\n",
      "413 9.767425945028663e-05\n",
      "414 9.489600051892921e-05\n",
      "415 9.219881030730903e-05\n",
      "416 8.958151011029258e-05\n",
      "417 8.703828643774614e-05\n",
      "418 8.457140938844532e-05\n",
      "419 8.217100548790768e-05\n",
      "420 7.983396062627435e-05\n",
      "421 7.757449930068105e-05\n",
      "422 7.53761560190469e-05\n",
      "423 7.324325270019472e-05\n",
      "424 7.116614142432809e-05\n",
      "425 6.915411358932033e-05\n",
      "426 6.719553493894637e-05\n",
      "427 6.529453821713105e-05\n",
      "428 6.344891153275967e-05\n",
      "429 6.165417289594188e-05\n",
      "430 5.9910151321673766e-05\n",
      "431 5.8216657635057345e-05\n",
      "432 5.6570748711237684e-05\n",
      "433 5.497592792380601e-05\n",
      "434 5.342347139958292e-05\n",
      "435 5.191637683310546e-05\n",
      "436 5.0450627895770594e-05\n",
      "437 4.902773434878327e-05\n",
      "438 4.7646833991166204e-05\n",
      "439 4.629991599358618e-05\n",
      "440 4.4999938836554065e-05\n",
      "441 4.372832700028084e-05\n",
      "442 4.249696576152928e-05\n",
      "443 4.129810258746147e-05\n",
      "444 4.013859143014997e-05\n",
      "445 3.9007012674119323e-05\n",
      "446 3.790963091887534e-05\n",
      "447 3.684523835545406e-05\n",
      "448 3.58070719812531e-05\n",
      "449 3.4802556911017746e-05\n",
      "450 3.3826356229837984e-05\n",
      "451 3.2876982004381716e-05\n",
      "452 3.1951592973200604e-05\n",
      "453 3.105577707174234e-05\n",
      "454 3.018443749169819e-05\n",
      "455 2.9336128136492334e-05\n",
      "456 2.8513031793409027e-05\n",
      "457 2.7712911105481908e-05\n",
      "458 2.6935236746794544e-05\n",
      "459 2.6181565772276372e-05\n",
      "460 2.544668677728623e-05\n",
      "461 2.4736074919928797e-05\n",
      "462 2.4043136363616213e-05\n",
      "463 2.336833676963579e-05\n",
      "464 2.271541416121181e-05\n",
      "465 2.208006480941549e-05\n",
      "466 2.1459558411152102e-05\n",
      "467 2.0860710719716735e-05\n",
      "468 2.0277102521504276e-05\n",
      "469 1.9711185814230703e-05\n",
      "470 1.9158049326506443e-05\n",
      "471 1.8622502466314472e-05\n",
      "472 1.8103577531292103e-05\n",
      "473 1.7597883925191127e-05\n",
      "474 1.710617470962461e-05\n",
      "475 1.6629566744086333e-05\n",
      "476 1.6164485714398324e-05\n",
      "477 1.5715415429440327e-05\n",
      "478 1.527713902760297e-05\n",
      "479 1.4850258594378829e-05\n",
      "480 1.4436616766033694e-05\n",
      "481 1.4032438230060507e-05\n",
      "482 1.3642606973007787e-05\n",
      "483 1.326167239312781e-05\n",
      "484 1.2892145605292171e-05\n",
      "485 1.2533178050944116e-05\n",
      "486 1.2185430932731833e-05\n",
      "487 1.1845209883176722e-05\n",
      "488 1.1515470760059543e-05\n",
      "489 1.1195203114766628e-05\n",
      "490 1.0884182302106638e-05\n",
      "491 1.0582387403701432e-05\n",
      "492 1.0288375960954e-05\n",
      "493 1.0002539966080803e-05\n",
      "494 9.723873517941684e-06\n",
      "495 9.453527127334382e-06\n",
      "496 9.191335266223177e-06\n",
      "497 8.937096936278977e-06\n",
      "498 8.687696208653506e-06\n",
      "499 8.446898391412105e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "# N是批大小；D是输入维度\n",
    "# H是隐藏层维度；D_out是输出维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "#创建输入和输出随机张量\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# 使用nn包将我们的模型定义为一系列的层\n",
    "# nn.Sequential是包含其他模块的模块，并按顺序应用这些模块来产生输出\n",
    "# 每个线性模型使用线性函数从输入计算输出，并保存其内部的权重和偏差张量\n",
    "# 在构造函数之后，我们使用.to()方法将其移动到所需的设备\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in,H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_out),\n",
    ")\n",
    "\n",
    "# nn包还包含常用的损失函数的定义；\n",
    "# 在这种情况下，我们将使用平均平方误差(MSE)作为我们的损失函数。\n",
    "# 设置reduction='sum'，表示我们计算的是平方误差的“和”，而不是平均值;\n",
    "# 这是为了与前面我们手工计算损失的例子保持一致，\n",
    "# 但是在实践中，通过设置reduction='elementwise_mean'来使用均方误差作为损失更为常见。\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # 前向传播：通过向模型传入x计算预测的y。\n",
    "    # 模块对象重载了__call__运算符，所以可以像函数那样调用它们。\n",
    "    # 这么做相当于向模块传入了一个张量，然后它返回了一个输出张量。\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 计算并打印损失。\n",
    "    # 传递包含y的预测值和真实值的张量，损失函数返回包含损失的张量。\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 反向传播之前清零梯度\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 反向传播：计算模型的损失对所有可学习参数的导数（梯度）。\n",
    "    # 在内部，每个模块的参数存储在requires_grad=True的张量中，\n",
    "    # 因此这个调用将计算模型中所有可学习参数的梯度。\n",
    "    loss.backward()\n",
    "\n",
    "    # 使用梯度下降更新权重。\n",
    "    # 每个参数都是张量，所以我们可以像我们以前那样可以得到它的数值和梯度\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 optim\n",
    "* 经常使用AdaGrad、RMSProp、Adam等更复杂的优化器来训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 644.5091552734375\n",
      "1 628.0556640625\n",
      "2 612.083984375\n",
      "3 596.6585693359375\n",
      "4 581.7081909179688\n",
      "5 567.1851806640625\n",
      "6 553.0217895507812\n",
      "7 539.255126953125\n",
      "8 525.9737548828125\n",
      "9 513.0512084960938\n",
      "10 500.5362243652344\n",
      "11 488.3689880371094\n",
      "12 476.60791015625\n",
      "13 465.21533203125\n",
      "14 454.0823669433594\n",
      "15 443.25543212890625\n",
      "16 432.7326354980469\n",
      "17 422.4562072753906\n",
      "18 412.4526672363281\n",
      "19 402.71893310546875\n",
      "20 393.2773132324219\n",
      "21 384.1584777832031\n",
      "22 375.2449951171875\n",
      "23 366.6287841796875\n",
      "24 358.34027099609375\n",
      "25 350.25775146484375\n",
      "26 342.3652038574219\n",
      "27 334.66204833984375\n",
      "28 327.11090087890625\n",
      "29 319.747802734375\n",
      "30 312.5738525390625\n",
      "31 305.5606384277344\n",
      "32 298.7122497558594\n",
      "33 292.01751708984375\n",
      "34 285.4820556640625\n",
      "35 279.0978698730469\n",
      "36 272.8434143066406\n",
      "37 266.6941833496094\n",
      "38 260.647216796875\n",
      "39 254.73548889160156\n",
      "40 248.9581298828125\n",
      "41 243.2889404296875\n",
      "42 237.73446655273438\n",
      "43 232.2922821044922\n",
      "44 226.9972381591797\n",
      "45 221.8069610595703\n",
      "46 216.7022705078125\n",
      "47 211.6923370361328\n",
      "48 206.766845703125\n",
      "49 201.93894958496094\n",
      "50 197.1998291015625\n",
      "51 192.556640625\n",
      "52 188.0128631591797\n",
      "53 183.56845092773438\n",
      "54 179.20480346679688\n",
      "55 174.92527770996094\n",
      "56 170.72401428222656\n",
      "57 166.60800170898438\n",
      "58 162.57974243164062\n",
      "59 158.62411499023438\n",
      "60 154.7385711669922\n",
      "61 150.92886352539062\n",
      "62 147.2104949951172\n",
      "63 143.55799865722656\n",
      "64 139.97305297851562\n",
      "65 136.45733642578125\n",
      "66 133.0106201171875\n",
      "67 129.61798095703125\n",
      "68 126.29362487792969\n",
      "69 123.04270935058594\n",
      "70 119.84901428222656\n",
      "71 116.71800231933594\n",
      "72 113.65108489990234\n",
      "73 110.63766479492188\n",
      "74 107.67963409423828\n",
      "75 104.77684020996094\n",
      "76 101.9374771118164\n",
      "77 99.15167999267578\n",
      "78 96.42376708984375\n",
      "79 93.75259399414062\n",
      "80 91.13744354248047\n",
      "81 88.57286071777344\n",
      "82 86.05474853515625\n",
      "83 83.59193420410156\n",
      "84 81.18355560302734\n",
      "85 78.82510375976562\n",
      "86 76.51483154296875\n",
      "87 74.25614929199219\n",
      "88 72.0444107055664\n",
      "89 69.88152313232422\n",
      "90 67.76808166503906\n",
      "91 65.70152282714844\n",
      "92 63.682464599609375\n",
      "93 61.711360931396484\n",
      "94 59.78414535522461\n",
      "95 57.905235290527344\n",
      "96 56.07274627685547\n",
      "97 54.28323745727539\n",
      "98 52.53840637207031\n",
      "99 50.83639144897461\n",
      "100 49.17710494995117\n",
      "101 47.558326721191406\n",
      "102 45.980220794677734\n",
      "103 44.443519592285156\n",
      "104 42.94581604003906\n",
      "105 41.48627853393555\n",
      "106 40.067222595214844\n",
      "107 38.68251037597656\n",
      "108 37.33683776855469\n",
      "109 36.029659271240234\n",
      "110 34.75756072998047\n",
      "111 33.523773193359375\n",
      "112 32.325096130371094\n",
      "113 31.160736083984375\n",
      "114 30.02884292602539\n",
      "115 28.932085037231445\n",
      "116 27.866931915283203\n",
      "117 26.832664489746094\n",
      "118 25.83048439025879\n",
      "119 24.856632232666016\n",
      "120 23.913171768188477\n",
      "121 22.999195098876953\n",
      "122 22.111543655395508\n",
      "123 21.253759384155273\n",
      "124 20.422685623168945\n",
      "125 19.618080139160156\n",
      "126 18.839473724365234\n",
      "127 18.086963653564453\n",
      "128 17.360145568847656\n",
      "129 16.656518936157227\n",
      "130 15.97729778289795\n",
      "131 15.321560859680176\n",
      "132 14.687769889831543\n",
      "133 14.077293395996094\n",
      "134 13.488348007202148\n",
      "135 12.918997764587402\n",
      "136 12.3699951171875\n",
      "137 11.84063720703125\n",
      "138 11.331291198730469\n",
      "139 10.841029167175293\n",
      "140 10.36866569519043\n",
      "141 9.913277626037598\n",
      "142 9.475515365600586\n",
      "143 9.05490493774414\n",
      "144 8.650495529174805\n",
      "145 8.261909484863281\n",
      "146 7.888836860656738\n",
      "147 7.531072616577148\n",
      "148 7.1866865158081055\n",
      "149 6.856448650360107\n",
      "150 6.539925575256348\n",
      "151 6.237011432647705\n",
      "152 5.946657180786133\n",
      "153 5.668310642242432\n",
      "154 5.402121543884277\n",
      "155 5.146772861480713\n",
      "156 4.902656555175781\n",
      "157 4.669240474700928\n",
      "158 4.446047782897949\n",
      "159 4.2326812744140625\n",
      "160 4.028598785400391\n",
      "161 3.833949565887451\n",
      "162 3.647695779800415\n",
      "163 3.470065116882324\n",
      "164 3.3004510402679443\n",
      "165 3.1387035846710205\n",
      "166 2.9843006134033203\n",
      "167 2.837336301803589\n",
      "168 2.6969990730285645\n",
      "169 2.5630178451538086\n",
      "170 2.4349944591522217\n",
      "171 2.312566041946411\n",
      "172 2.1954991817474365\n",
      "173 2.084005117416382\n",
      "174 1.9778518676757812\n",
      "175 1.8766955137252808\n",
      "176 1.78030264377594\n",
      "177 1.6885719299316406\n",
      "178 1.6013001203536987\n",
      "179 1.518249750137329\n",
      "180 1.4393643140792847\n",
      "181 1.3644697666168213\n",
      "182 1.293358564376831\n",
      "183 1.2258663177490234\n",
      "184 1.161800742149353\n",
      "185 1.1010972261428833\n",
      "186 1.0434398651123047\n",
      "187 0.9887380599975586\n",
      "188 0.9367694854736328\n",
      "189 0.8874990344047546\n",
      "190 0.8407533168792725\n",
      "191 0.7963951826095581\n",
      "192 0.7542850375175476\n",
      "193 0.7143923044204712\n",
      "194 0.6765395402908325\n",
      "195 0.6406670808792114\n",
      "196 0.6067015528678894\n",
      "197 0.574468731880188\n",
      "198 0.5439770221710205\n",
      "199 0.5150713920593262\n",
      "200 0.48768875002861023\n",
      "201 0.46177050471305847\n",
      "202 0.4372194707393646\n",
      "203 0.41394689679145813\n",
      "204 0.3919464349746704\n",
      "205 0.37113216519355774\n",
      "206 0.3514179289340973\n",
      "207 0.3327823281288147\n",
      "208 0.3151271343231201\n",
      "209 0.2984263002872467\n",
      "210 0.28260812163352966\n",
      "211 0.26765358448028564\n",
      "212 0.25347986817359924\n",
      "213 0.2400885820388794\n",
      "214 0.22742320597171783\n",
      "215 0.21543660759925842\n",
      "216 0.20410071313381195\n",
      "217 0.19336523115634918\n",
      "218 0.18319490551948547\n",
      "219 0.1735813319683075\n",
      "220 0.16447874903678894\n",
      "221 0.15586663782596588\n",
      "222 0.14770931005477905\n",
      "223 0.14006569981575012\n",
      "224 0.1328381448984146\n",
      "225 0.12599162757396698\n",
      "226 0.11950644105672836\n",
      "227 0.11336728930473328\n",
      "228 0.10755430161952972\n",
      "229 0.10204725712537766\n",
      "230 0.09683053195476532\n",
      "231 0.09188813716173172\n",
      "232 0.08721239864826202\n",
      "233 0.082772396504879\n",
      "234 0.0785766988992691\n",
      "235 0.07458909600973129\n",
      "236 0.07081060856580734\n",
      "237 0.06723068654537201\n",
      "238 0.06383905559778214\n",
      "239 0.06062273308634758\n",
      "240 0.057571250945329666\n",
      "241 0.054678816348314285\n",
      "242 0.051933497190475464\n",
      "243 0.04932818189263344\n",
      "244 0.04685777798295021\n",
      "245 0.04451313242316246\n",
      "246 0.04228682070970535\n",
      "247 0.04017259180545807\n",
      "248 0.03816761448979378\n",
      "249 0.03626471757888794\n",
      "250 0.03445480391383171\n",
      "251 0.0327373743057251\n",
      "252 0.031107023358345032\n",
      "253 0.029558777809143066\n",
      "254 0.028088372200727463\n",
      "255 0.026691285893321037\n",
      "256 0.025366375222802162\n",
      "257 0.024105487391352654\n",
      "258 0.02290923148393631\n",
      "259 0.021773383021354675\n",
      "260 0.02069510519504547\n",
      "261 0.019669676199555397\n",
      "262 0.018695730715990067\n",
      "263 0.017770176753401756\n",
      "264 0.01689116656780243\n",
      "265 0.016055971384048462\n",
      "266 0.015262431465089321\n",
      "267 0.014508817344903946\n",
      "268 0.013792052865028381\n",
      "269 0.013111318461596966\n",
      "270 0.012464243918657303\n",
      "271 0.011849961243569851\n",
      "272 0.011265207082033157\n",
      "273 0.010709844529628754\n",
      "274 0.010182197205722332\n",
      "275 0.009680542163550854\n",
      "276 0.009204031899571419\n",
      "277 0.008751479908823967\n",
      "278 0.008321334607899189\n",
      "279 0.007911955937743187\n",
      "280 0.007523172069340944\n",
      "281 0.007153732236474752\n",
      "282 0.006802648771554232\n",
      "283 0.00646893959492445\n",
      "284 0.006151779554784298\n",
      "285 0.005850548855960369\n",
      "286 0.0055638886988162994\n",
      "287 0.005291654262691736\n",
      "288 0.005032888147979975\n",
      "289 0.004787002224475145\n",
      "290 0.004553244449198246\n",
      "291 0.004331198520958424\n",
      "292 0.0041200341656804085\n",
      "293 0.003919388633221388\n",
      "294 0.003728666342794895\n",
      "295 0.003547453321516514\n",
      "296 0.00337520195171237\n",
      "297 0.003211670322343707\n",
      "298 0.0030558889266103506\n",
      "299 0.002908009337261319\n",
      "300 0.0027674606535583735\n",
      "301 0.0026339013129472733\n",
      "302 0.0025068509858101606\n",
      "303 0.0023862377274781466\n",
      "304 0.002271454082801938\n",
      "305 0.002162402030080557\n",
      "306 0.002058747224509716\n",
      "307 0.001960188150405884\n",
      "308 0.001866471255198121\n",
      "309 0.0017774122534319758\n",
      "310 0.0016927130054682493\n",
      "311 0.0016121998196467757\n",
      "312 0.0015356459189206362\n",
      "313 0.0014629637589678168\n",
      "314 0.0013936391333118081\n",
      "315 0.001327855046838522\n",
      "316 0.0012652523582801223\n",
      "317 0.0012057141866534948\n",
      "318 0.0011491263285279274\n",
      "319 0.0010952675947919488\n",
      "320 0.0010440548649057746\n",
      "321 0.0009953163098543882\n",
      "322 0.0009489523363299668\n",
      "323 0.0009048328502103686\n",
      "324 0.0008628725190646946\n",
      "325 0.0008229431696236134\n",
      "326 0.0007849391549825668\n",
      "327 0.0007487800321541727\n",
      "328 0.0007143402472138405\n",
      "329 0.0006815703818574548\n",
      "330 0.0006503720651380718\n",
      "331 0.0006206628168001771\n",
      "332 0.0005923804128542542\n",
      "333 0.0005654593696817756\n",
      "334 0.0005397906061261892\n",
      "335 0.0005153561942279339\n",
      "336 0.0004920889623463154\n",
      "337 0.00046991786803118885\n",
      "338 0.0004487853730097413\n",
      "339 0.0004286543990019709\n",
      "340 0.0004094910982530564\n",
      "341 0.0003912042884621769\n",
      "342 0.0003737792430911213\n",
      "343 0.00035717186983674765\n",
      "344 0.00034134750603698194\n",
      "345 0.000326269626384601\n",
      "346 0.0003118542372249067\n",
      "347 0.00029813035507686436\n",
      "348 0.00028504419606179\n",
      "349 0.00027255096938461065\n",
      "350 0.00026064185658469796\n",
      "351 0.0002492718631401658\n",
      "352 0.00023842958034947515\n",
      "353 0.00022807168716099113\n",
      "354 0.00021818428649567068\n",
      "355 0.000208751080208458\n",
      "356 0.00019974472525063902\n",
      "357 0.00019114559108857065\n",
      "358 0.00018293558969162405\n",
      "359 0.00017508631572127342\n",
      "360 0.00016759334539528936\n",
      "361 0.0001604383869562298\n",
      "362 0.00015359393728431314\n",
      "363 0.0001470566203352064\n",
      "364 0.00014081003610044718\n",
      "365 0.00013483875954989344\n",
      "366 0.00012912662350572646\n",
      "367 0.00012367067392915487\n",
      "368 0.0001184507564175874\n",
      "369 0.00011346406245138496\n",
      "370 0.00010868837125599384\n",
      "371 0.0001041189898387529\n",
      "372 9.975633292924613e-05\n",
      "373 9.557909652357921e-05\n",
      "374 9.157999738818035e-05\n",
      "375 8.77525526448153e-05\n",
      "376 8.409102156292647e-05\n",
      "377 8.059145329752937e-05\n",
      "378 7.723491580691189e-05\n",
      "379 7.402403571177274e-05\n",
      "380 7.094712054822594e-05\n",
      "381 6.800374831072986e-05\n",
      "382 6.518490408780053e-05\n",
      "383 6.248730642255396e-05\n",
      "384 5.989893907099031e-05\n",
      "385 5.7417859352426603e-05\n",
      "386 5.504711953108199e-05\n",
      "387 5.277181480778381e-05\n",
      "388 5.059345130575821e-05\n",
      "389 4.8503650759812444e-05\n",
      "390 4.65042503492441e-05\n",
      "391 4.458523108041845e-05\n",
      "392 4.274928869563155e-05\n",
      "393 4.0986786189023405e-05\n",
      "394 3.9298822230193764e-05\n",
      "395 3.768128954106942e-05\n",
      "396 3.612904038163833e-05\n",
      "397 3.464250039542094e-05\n",
      "398 3.321905751363374e-05\n",
      "399 3.18512502417434e-05\n",
      "400 3.054054468520917e-05\n",
      "401 2.928460162365809e-05\n",
      "402 2.8079261028324254e-05\n",
      "403 2.692402085813228e-05\n",
      "404 2.5816021661739796e-05\n",
      "405 2.4752987883402966e-05\n",
      "406 2.3733302441542037e-05\n",
      "407 2.275547740282491e-05\n",
      "408 2.181725540140178e-05\n",
      "409 2.0918905647704378e-05\n",
      "410 2.005727401410695e-05\n",
      "411 1.9228760720579885e-05\n",
      "412 1.8435472156852484e-05\n",
      "413 1.7673652109806426e-05\n",
      "414 1.6944073649938218e-05\n",
      "415 1.624351534701418e-05\n",
      "416 1.557151881570462e-05\n",
      "417 1.4926305993867572e-05\n",
      "418 1.4308560821518768e-05\n",
      "419 1.3715259228774812e-05\n",
      "420 1.314648579864297e-05\n",
      "421 1.2600555237440858e-05\n",
      "422 1.2077335668436717e-05\n",
      "423 1.1574556083360221e-05\n",
      "424 1.109271943278145e-05\n",
      "425 1.0630596079863608e-05\n",
      "426 1.0187218322244007e-05\n",
      "427 9.761978617461864e-06\n",
      "428 9.354460416943766e-06\n",
      "429 8.963344043877441e-06\n",
      "430 8.587920092395507e-06\n",
      "431 8.227789294323884e-06\n",
      "432 7.882710633566603e-06\n",
      "433 7.552264378318796e-06\n",
      "434 7.2345765147474594e-06\n",
      "435 6.929637038410874e-06\n",
      "436 6.638018476223806e-06\n",
      "437 6.357921847666148e-06\n",
      "438 6.0888751249876805e-06\n",
      "439 5.831832368130563e-06\n",
      "440 5.585229246207746e-06\n",
      "441 5.3478711379284505e-06\n",
      "442 5.1209576668043155e-06\n",
      "443 4.90314960188698e-06\n",
      "444 4.6943509914854076e-06\n",
      "445 4.494360837270506e-06\n",
      "446 4.302714387449669e-06\n",
      "447 4.1185148802469485e-06\n",
      "448 3.9426454350177664e-06\n",
      "449 3.773322077904595e-06\n",
      "450 3.6116125556873158e-06\n",
      "451 3.456126478340593e-06\n",
      "452 3.3076821637223475e-06\n",
      "453 3.165138423355529e-06\n",
      "454 3.0285816592368064e-06\n",
      "455 2.8974864108022302e-06\n",
      "456 2.7718988349079154e-06\n",
      "457 2.6521936433709925e-06\n",
      "458 2.5371612082381034e-06\n",
      "459 2.426937271593488e-06\n",
      "460 2.3206866899272427e-06\n",
      "461 2.220061787738814e-06\n",
      "462 2.122661953762872e-06\n",
      "463 2.0299082734709373e-06\n",
      "464 1.941011532835546e-06\n",
      "465 1.856180915638106e-06\n",
      "466 1.774345378180442e-06\n",
      "467 1.6962140989562613e-06\n",
      "468 1.6215691402976518e-06\n",
      "469 1.5498965240112739e-06\n",
      "470 1.4814168025623076e-06\n",
      "471 1.4156768202155945e-06\n",
      "472 1.353037873741414e-06\n",
      "473 1.2930529464938445e-06\n",
      "474 1.2355611715975101e-06\n",
      "475 1.1806165503003285e-06\n",
      "476 1.1276923714831355e-06\n",
      "477 1.0772772611744585e-06\n",
      "478 1.028996621244005e-06\n",
      "479 9.827863323152997e-07\n",
      "480 9.388029411638854e-07\n",
      "481 8.968722227109538e-07\n",
      "482 8.561905815440696e-07\n",
      "483 8.1764534343165e-07\n",
      "484 7.8096081779222e-07\n",
      "485 7.454805199813563e-07\n",
      "486 7.115730227269523e-07\n",
      "487 6.791589157728595e-07\n",
      "488 6.485230414909893e-07\n",
      "489 6.188466841194895e-07\n",
      "490 5.905308739784232e-07\n",
      "491 5.636388777929824e-07\n",
      "492 5.376405169954523e-07\n",
      "493 5.13142254021659e-07\n",
      "494 4.894848757430736e-07\n",
      "495 4.670849591548176e-07\n",
      "496 4.4568307089321024e-07\n",
      "497 4.2488485973990464e-07\n",
      "498 4.052598967518861e-07\n",
      "499 3.865020516968798e-07\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# N是批大小；D是输入维度\n",
    "# H是隐藏层维度；D_out是输出维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 产生随机输入和输出张量\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# 使用nn包定义模型和损失函数\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in,H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# 使用optim包定义优化器（Optimizer）。Optimizer将会为我们更新模型的权重。\n",
    "# 这里我们使用Adam优化方法；optim包还包含了许多别的优化算法。\n",
    "# Adam构造函数的第一个参数告诉优化器应该更新哪些张量。\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for t in range(500):\n",
    "    # 前向传播\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 计算并打印loss\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 反向传播之前，使用optimizer将它要更新的所有张量的梯度清零（这些张量是模型了学习的权重）\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #反向传播：根据模型的参数计算loss的梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 调用Optimizer的step函数使它所有参数更新\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 自定义nn模块\n",
    "* 有时候需要指定比现有模块序列更复杂的模型\n",
    "* 可以通过继承nn.Module并定义forward函数\n",
    "    * forward函数可以 使用其他模块或者其他的自动求导运算来接收输入tensor，产生输出tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 668.4197998046875\n",
      "1 619.9055786132812\n",
      "2 578.0693359375\n",
      "3 541.159423828125\n",
      "4 508.06500244140625\n",
      "5 478.2771301269531\n",
      "6 451.5179443359375\n",
      "7 427.119140625\n",
      "8 404.54608154296875\n",
      "9 383.47979736328125\n",
      "10 363.629638671875\n",
      "11 345.1078796386719\n",
      "12 327.6806335449219\n",
      "13 311.0830993652344\n",
      "14 295.2127685546875\n",
      "15 280.16778564453125\n",
      "16 265.842041015625\n",
      "17 252.17208862304688\n",
      "18 239.162109375\n",
      "19 226.72271728515625\n",
      "20 214.81137084960938\n",
      "21 203.3628387451172\n",
      "22 192.39163208007812\n",
      "23 181.94094848632812\n",
      "24 171.95425415039062\n",
      "25 162.38058471679688\n",
      "26 153.24365234375\n",
      "27 144.55514526367188\n",
      "28 136.25144958496094\n",
      "29 128.3736572265625\n",
      "30 120.91014862060547\n",
      "31 113.84162902832031\n",
      "32 107.14134979248047\n",
      "33 100.78973388671875\n",
      "34 94.78108215332031\n",
      "35 89.10570526123047\n",
      "36 83.73550415039062\n",
      "37 78.66990661621094\n",
      "38 73.89200592041016\n",
      "39 69.38213348388672\n",
      "40 65.1190185546875\n",
      "41 61.10478210449219\n",
      "42 57.3365592956543\n",
      "43 53.801700592041016\n",
      "44 50.48366928100586\n",
      "45 47.37499237060547\n",
      "46 44.45392608642578\n",
      "47 41.71592712402344\n",
      "48 39.1529655456543\n",
      "49 36.757938385009766\n",
      "50 34.51538848876953\n",
      "51 32.415977478027344\n",
      "52 30.45522117614746\n",
      "53 28.623260498046875\n",
      "54 26.91067886352539\n",
      "55 25.308650970458984\n",
      "56 23.80858039855957\n",
      "57 22.406064987182617\n",
      "58 21.096155166625977\n",
      "59 19.86919593811035\n",
      "60 18.7207088470459\n",
      "61 17.647550582885742\n",
      "62 16.643844604492188\n",
      "63 15.705239295959473\n",
      "64 14.827367782592773\n",
      "65 14.005911827087402\n",
      "66 13.236316680908203\n",
      "67 12.515541076660156\n",
      "68 11.83969497680664\n",
      "69 11.206774711608887\n",
      "70 10.613407135009766\n",
      "71 10.055826187133789\n",
      "72 9.533616065979004\n",
      "73 9.043242454528809\n",
      "74 8.582377433776855\n",
      "75 8.148837089538574\n",
      "76 7.7417216300964355\n",
      "77 7.358738422393799\n",
      "78 6.99787712097168\n",
      "79 6.659409523010254\n",
      "80 6.340831279754639\n",
      "81 6.040754318237305\n",
      "82 5.7583088874816895\n",
      "83 5.492088317871094\n",
      "84 5.240846633911133\n",
      "85 5.00377082824707\n",
      "86 4.779993057250977\n",
      "87 4.568174362182617\n",
      "88 4.368115425109863\n",
      "89 4.179242134094238\n",
      "90 4.001120567321777\n",
      "91 3.832226276397705\n",
      "92 3.672795534133911\n",
      "93 3.521566390991211\n",
      "94 3.37821102142334\n",
      "95 3.2423927783966064\n",
      "96 3.113332986831665\n",
      "97 2.9908831119537354\n",
      "98 2.8745319843292236\n",
      "99 2.764028310775757\n",
      "100 2.659036159515381\n",
      "101 2.5590693950653076\n",
      "102 2.4640302658081055\n",
      "103 2.3736424446105957\n",
      "104 2.2876336574554443\n",
      "105 2.2056212425231934\n",
      "106 2.127448558807373\n",
      "107 2.0529308319091797\n",
      "108 1.98185133934021\n",
      "109 1.9140106439590454\n",
      "110 1.849210262298584\n",
      "111 1.7873485088348389\n",
      "112 1.7281543016433716\n",
      "113 1.6715474128723145\n",
      "114 1.6173428297042847\n",
      "115 1.5655009746551514\n",
      "116 1.5159149169921875\n",
      "117 1.4685624837875366\n",
      "118 1.423207402229309\n",
      "119 1.3797608613967896\n",
      "120 1.338029146194458\n",
      "121 1.2980762720108032\n",
      "122 1.2596914768218994\n",
      "123 1.2228405475616455\n",
      "124 1.1874722242355347\n",
      "125 1.153505802154541\n",
      "126 1.1208897829055786\n",
      "127 1.089540958404541\n",
      "128 1.0593578815460205\n",
      "129 1.0303196907043457\n",
      "130 1.0023349523544312\n",
      "131 0.9754043221473694\n",
      "132 0.9494451284408569\n",
      "133 0.9244157671928406\n",
      "134 0.9002910256385803\n",
      "135 0.877008855342865\n",
      "136 0.8545466661453247\n",
      "137 0.8328292965888977\n",
      "138 0.8118900656700134\n",
      "139 0.7916622161865234\n",
      "140 0.772063136100769\n",
      "141 0.7531203627586365\n",
      "142 0.7348018288612366\n",
      "143 0.7170700430870056\n",
      "144 0.6999173164367676\n",
      "145 0.683312714099884\n",
      "146 0.6672093868255615\n",
      "147 0.6516005992889404\n",
      "148 0.6364699006080627\n",
      "149 0.6217312812805176\n",
      "150 0.6074293851852417\n",
      "151 0.5935773849487305\n",
      "152 0.5805963277816772\n",
      "153 0.5680761933326721\n",
      "154 0.5559377074241638\n",
      "155 0.5441465973854065\n",
      "156 0.5326985120773315\n",
      "157 0.521595299243927\n",
      "158 0.5108006596565247\n",
      "159 0.5003113150596619\n",
      "160 0.49011939764022827\n",
      "161 0.48020175099372864\n",
      "162 0.4705522656440735\n",
      "163 0.46115800738334656\n",
      "164 0.45201483368873596\n",
      "165 0.443115234375\n",
      "166 0.4344453811645508\n",
      "167 0.42599615454673767\n",
      "168 0.4177541136741638\n",
      "169 0.4097151458263397\n",
      "170 0.4018799066543579\n",
      "171 0.39424020051956177\n",
      "172 0.3867809474468231\n",
      "173 0.37949711084365845\n",
      "174 0.37238794565200806\n",
      "175 0.3654501438140869\n",
      "176 0.3586691617965698\n",
      "177 0.3520435392856598\n",
      "178 0.34557870030403137\n",
      "179 0.3392518162727356\n",
      "180 0.33306464552879333\n",
      "181 0.32701894640922546\n",
      "182 0.321100652217865\n",
      "183 0.31531384587287903\n",
      "184 0.3096541464328766\n",
      "185 0.30411213636398315\n",
      "186 0.29868802428245544\n",
      "187 0.2933773696422577\n",
      "188 0.2881763279438019\n",
      "189 0.28307977318763733\n",
      "190 0.27809032797813416\n",
      "191 0.27320343255996704\n",
      "192 0.2684059143066406\n",
      "193 0.26370885968208313\n",
      "194 0.25910764932632446\n",
      "195 0.2545928359031677\n",
      "196 0.2501712143421173\n",
      "197 0.24583588540554047\n",
      "198 0.24158070981502533\n",
      "199 0.23740608990192413\n",
      "200 0.23331400752067566\n",
      "201 0.22930176556110382\n",
      "202 0.22536234557628632\n",
      "203 0.22149960696697235\n",
      "204 0.21771036088466644\n",
      "205 0.2139882594347\n",
      "206 0.21033424139022827\n",
      "207 0.20674921572208405\n",
      "208 0.20322975516319275\n",
      "209 0.19977198541164398\n",
      "210 0.19637663662433624\n",
      "211 0.19304604828357697\n",
      "212 0.18977132439613342\n",
      "213 0.18655584752559662\n",
      "214 0.18339836597442627\n",
      "215 0.1802964210510254\n",
      "216 0.17724929749965668\n",
      "217 0.1742548793554306\n",
      "218 0.17131344974040985\n",
      "219 0.168422132730484\n",
      "220 0.1655808389186859\n",
      "221 0.16279065608978271\n",
      "222 0.1600469946861267\n",
      "223 0.15735013782978058\n",
      "224 0.15469896793365479\n",
      "225 0.1520957350730896\n",
      "226 0.14953432977199554\n",
      "227 0.1470165252685547\n",
      "228 0.14454185962677002\n",
      "229 0.14211015403270721\n",
      "230 0.13971805572509766\n",
      "231 0.13736745715141296\n",
      "232 0.13505636155605316\n",
      "233 0.13278396427631378\n",
      "234 0.1305485963821411\n",
      "235 0.12835028767585754\n",
      "236 0.1261899769306183\n",
      "237 0.12406452000141144\n",
      "238 0.12197385728359222\n",
      "239 0.1199188232421875\n",
      "240 0.11789873987436295\n",
      "241 0.11591034382581711\n",
      "242 0.11395514011383057\n",
      "243 0.11203325539827347\n",
      "244 0.1101435050368309\n",
      "245 0.10828444361686707\n",
      "246 0.10645607858896255\n",
      "247 0.10465922951698303\n",
      "248 0.10289130359888077\n",
      "249 0.10115166753530502\n",
      "250 0.09944052994251251\n",
      "251 0.09775892645120621\n",
      "252 0.09610388427972794\n",
      "253 0.09447621554136276\n",
      "254 0.09287561476230621\n",
      "255 0.09130263328552246\n",
      "256 0.08975359052419662\n",
      "257 0.08823046833276749\n",
      "258 0.08673317730426788\n",
      "259 0.08526130765676498\n",
      "260 0.08381225168704987\n",
      "261 0.08238724619150162\n",
      "262 0.08098594844341278\n",
      "263 0.07960835844278336\n",
      "264 0.07825233042240143\n",
      "265 0.07691836357116699\n",
      "266 0.07560665160417557\n",
      "267 0.07431717216968536\n",
      "268 0.0730476975440979\n",
      "269 0.07179923355579376\n",
      "270 0.07056421041488647\n",
      "271 0.06935074180364609\n",
      "272 0.06815677136182785\n",
      "273 0.06698273867368698\n",
      "274 0.06582841277122498\n",
      "275 0.06469394266605377\n",
      "276 0.06357770413160324\n",
      "277 0.06247984245419502\n",
      "278 0.06140067055821419\n",
      "279 0.06034069508314133\n",
      "280 0.059297095984220505\n",
      "281 0.0582708939909935\n",
      "282 0.05726182460784912\n",
      "283 0.05627039074897766\n",
      "284 0.05529467388987541\n",
      "285 0.0543350949883461\n",
      "286 0.05339149758219719\n",
      "287 0.05246445909142494\n",
      "288 0.05155213922262192\n",
      "289 0.05065501481294632\n",
      "290 0.049772750586271286\n",
      "291 0.048906125128269196\n",
      "292 0.048053257167339325\n",
      "293 0.047214992344379425\n",
      "294 0.04639064520597458\n",
      "295 0.04558064416050911\n",
      "296 0.04478387162089348\n",
      "297 0.04400000721216202\n",
      "298 0.043229833245277405\n",
      "299 0.04247276484966278\n",
      "300 0.04172840714454651\n",
      "301 0.04099613055586815\n",
      "302 0.04027621075510979\n",
      "303 0.039568718522787094\n",
      "304 0.03887338936328888\n",
      "305 0.03818947821855545\n",
      "306 0.03751710057258606\n",
      "307 0.03685634955763817\n",
      "308 0.03620694577693939\n",
      "309 0.03556829318404198\n",
      "310 0.034940194338560104\n",
      "311 0.034322816878557205\n",
      "312 0.03371640667319298\n",
      "313 0.033120047301054\n",
      "314 0.032533615827560425\n",
      "315 0.03195721656084061\n",
      "316 0.03139090910553932\n",
      "317 0.030834363773465157\n",
      "318 0.03028683550655842\n",
      "319 0.029748721048235893\n",
      "320 0.029219962656497955\n",
      "321 0.028700485825538635\n",
      "322 0.02818954363465309\n",
      "323 0.02768721431493759\n",
      "324 0.027193672955036163\n",
      "325 0.026708990335464478\n",
      "326 0.026232291013002396\n",
      "327 0.025763697922229767\n",
      "328 0.02530321292579174\n",
      "329 0.02485128678381443\n",
      "330 0.02440660074353218\n",
      "331 0.023969538509845734\n",
      "332 0.023539962247014046\n",
      "333 0.02311788871884346\n",
      "334 0.022703371942043304\n",
      "335 0.022295717149972916\n",
      "336 0.02189512364566326\n",
      "337 0.021501539275050163\n",
      "338 0.021114932373166084\n",
      "339 0.020734937861561775\n",
      "340 0.02036135271191597\n",
      "341 0.019994404166936874\n",
      "342 0.019633978605270386\n",
      "343 0.0192799624055624\n",
      "344 0.01893174648284912\n",
      "345 0.018589677289128304\n",
      "346 0.018253589048981667\n",
      "347 0.017923688516020775\n",
      "348 0.017599336802959442\n",
      "349 0.017280593514442444\n",
      "350 0.01696748286485672\n",
      "351 0.016659939661622047\n",
      "352 0.016357911750674248\n",
      "353 0.016061246395111084\n",
      "354 0.015769684687256813\n",
      "355 0.01548335887491703\n",
      "356 0.015202188864350319\n",
      "357 0.014925793744623661\n",
      "358 0.014654276892542839\n",
      "359 0.014387525618076324\n",
      "360 0.014125644229352474\n",
      "361 0.013868340291082859\n",
      "362 0.013615550473332405\n",
      "363 0.01336723007261753\n",
      "364 0.013123263604938984\n",
      "365 0.01288388017565012\n",
      "366 0.012648526579141617\n",
      "367 0.012417301535606384\n",
      "368 0.012190231122076511\n",
      "369 0.011967197991907597\n",
      "370 0.011748351156711578\n",
      "371 0.011533178389072418\n",
      "372 0.011321797966957092\n",
      "373 0.011114250868558884\n",
      "374 0.010910534299910069\n",
      "375 0.010710366070270538\n",
      "376 0.010513716377317905\n",
      "377 0.010320580564439297\n",
      "378 0.010130944661796093\n",
      "379 0.009944825433194637\n",
      "380 0.009761924855411053\n",
      "381 0.009582293219864368\n",
      "382 0.009405863471329212\n",
      "383 0.009232775308191776\n",
      "384 0.009062634781002998\n",
      "385 0.008895566686987877\n",
      "386 0.008731522597372532\n",
      "387 0.008570414036512375\n",
      "388 0.008412299677729607\n",
      "389 0.008256991393864155\n",
      "390 0.008104385808110237\n",
      "391 0.007954612374305725\n",
      "392 0.0078075239434838295\n",
      "393 0.007663227617740631\n",
      "394 0.0075213913805782795\n",
      "395 0.007382150739431381\n",
      "396 0.007245450746268034\n",
      "397 0.007111202925443649\n",
      "398 0.006979475263506174\n",
      "399 0.006850068457424641\n",
      "400 0.006722999271005392\n",
      "401 0.006598200183361769\n",
      "402 0.0064757224172353745\n",
      "403 0.006355514284223318\n",
      "404 0.006237455178052187\n",
      "405 0.006121461279690266\n",
      "406 0.006007649470120668\n",
      "407 0.005895936395972967\n",
      "408 0.005786257795989513\n",
      "409 0.0056785885244607925\n",
      "410 0.005572800524532795\n",
      "411 0.005469017196446657\n",
      "412 0.005367152392864227\n",
      "413 0.005267124157398939\n",
      "414 0.005168956704437733\n",
      "415 0.005072480998933315\n",
      "416 0.0049778311513364315\n",
      "417 0.004885036498308182\n",
      "418 0.004793924745172262\n",
      "419 0.004704438149929047\n",
      "420 0.004616617690771818\n",
      "421 0.004530391190201044\n",
      "422 0.004445801489055157\n",
      "423 0.004362757783383131\n",
      "424 0.004281201865524054\n",
      "425 0.004201157484203577\n",
      "426 0.004122603684663773\n",
      "427 0.004045506007969379\n",
      "428 0.00396981555968523\n",
      "429 0.003895529080182314\n",
      "430 0.0038225785829126835\n",
      "431 0.0037509745452553034\n",
      "432 0.0036807467695325613\n",
      "433 0.0036117923445999622\n",
      "434 0.00354407774284482\n",
      "435 0.0034776211250573397\n",
      "436 0.003412379417568445\n",
      "437 0.0033484117593616247\n",
      "438 0.0032855854369699955\n",
      "439 0.003223926294595003\n",
      "440 0.003163400571793318\n",
      "441 0.003103982424363494\n",
      "442 0.0030458844266831875\n",
      "443 0.0029890243895351887\n",
      "444 0.0029332193080335855\n",
      "445 0.0028784414753317833\n",
      "446 0.002824669238179922\n",
      "447 0.0027719559147953987\n",
      "448 0.002720167627558112\n",
      "449 0.00266933161765337\n",
      "450 0.002619426231831312\n",
      "451 0.0025704726576805115\n",
      "452 0.0025224359706044197\n",
      "453 0.0024752700701355934\n",
      "454 0.002428995445370674\n",
      "455 0.00238353805616498\n",
      "456 0.0023389370180666447\n",
      "457 0.0022951862774789333\n",
      "458 0.0022522518411278725\n",
      "459 0.002210079925134778\n",
      "460 0.0021686910185962915\n",
      "461 0.0021280748769640923\n",
      "462 0.002088232198730111\n",
      "463 0.002049119444563985\n",
      "464 0.00201070006005466\n",
      "465 0.0019730390049517155\n",
      "466 0.0019360108999535441\n",
      "467 0.0018997349543496966\n",
      "468 0.0018641159404069185\n",
      "469 0.001829159795306623\n",
      "470 0.001794834272004664\n",
      "471 0.001761161838658154\n",
      "472 0.0017281020991504192\n",
      "473 0.0016956792678683996\n",
      "474 0.0016638401430100203\n",
      "475 0.0016325918259099126\n",
      "476 0.001601914525963366\n",
      "477 0.0015718284994363785\n",
      "478 0.001542305457405746\n",
      "479 0.0015133185079321265\n",
      "480 0.001484864391386509\n",
      "481 0.0014569584745913744\n",
      "482 0.0014295579167082906\n",
      "483 0.0014026829740032554\n",
      "484 0.0013763108290731907\n",
      "485 0.0013503886293619871\n",
      "486 0.0013249830808490515\n",
      "487 0.001300046220421791\n",
      "488 0.0012755799107253551\n",
      "489 0.0012515857815742493\n",
      "490 0.0012280127266421914\n",
      "491 0.0012048748321831226\n",
      "492 0.0011821710504591465\n",
      "493 0.00115990883205086\n",
      "494 0.0011380667565390468\n",
      "495 0.0011166083859279752\n",
      "496 0.0010955651523545384\n",
      "497 0.0010749130742624402\n",
      "498 0.0010546479607000947\n",
      "499 0.0010347638744860888\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        \"\"\"\n",
    "        在构造函数中，我们实例化了两个nn.Linear模块，并将它们作为成员变量。\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet,self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in,H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        在前向传播的函数中，我们接收一个输入的张量，也必须返回一个输出张量。\n",
    "        我们可以使用构造函数中定义的模块以及张量上的任意的（可微分的）操作。\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "# N是批大小； D_in 是输入维度；\n",
    "# H 是隐藏层维度； D_out 是输出维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 产生输入和输出的随机张量\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# 通过实例化上面定义的类来构建我们的模型。\n",
    "model = TwoLayerNet(D_in,H,D_out)\n",
    "\n",
    "# 构造损失函数和优化器。\n",
    "# SGD构造函数中对model.parameters()的调用，\n",
    "# 将包含模型的一部分，即两个nn.Linear模块的可学习参数\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4)\n",
    "for t in range(500):\n",
    "    # 前向传播：通过向模型传递x计算预测值y\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 计算并输出loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 清零梯度，反向传播，更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 控制流和权重共享\n",
    "* 一个非常奇怪的模型：一个全连接的ReLU网络，在每一次前向传播时，它的隐藏层的层数为随机1到4之间的数，这样可以多次重用相同的权重来计算\n",
    "* 这个模型可以使用普通的Python流控制来实现循环，并且我们可以通过在定义转发时多次重用同一个模块来实现最内层之间的权重共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 687.6044311523438\n",
      "1 682.154052734375\n",
      "2 702.1114501953125\n",
      "3 676.8717041015625\n",
      "4 655.7037963867188\n",
      "5 643.1021728515625\n",
      "6 551.3598022460938\n",
      "7 613.149658203125\n",
      "8 463.871826171875\n",
      "9 671.9547729492188\n",
      "10 657.5535278320312\n",
      "11 669.3069458007812\n",
      "12 556.9661254882812\n",
      "13 665.1159057617188\n",
      "14 662.1488647460938\n",
      "15 658.3453369140625\n",
      "16 503.13421630859375\n",
      "17 624.1324462890625\n",
      "18 613.20947265625\n",
      "19 598.17919921875\n",
      "20 421.0908203125\n",
      "21 558.5306396484375\n",
      "22 596.1558837890625\n",
      "23 343.4128112792969\n",
      "24 481.06268310546875\n",
      "25 290.43597412109375\n",
      "26 262.6957092285156\n",
      "27 481.725830078125\n",
      "28 361.64501953125\n",
      "29 329.435302734375\n",
      "30 199.8596954345703\n",
      "31 277.08319091796875\n",
      "32 283.4720458984375\n",
      "33 239.2086639404297\n",
      "34 296.52764892578125\n",
      "35 207.5323486328125\n",
      "36 185.3970947265625\n",
      "37 170.26840209960938\n",
      "38 210.61134338378906\n",
      "39 204.0251007080078\n",
      "40 145.60055541992188\n",
      "41 155.42044067382812\n",
      "42 165.08348083496094\n",
      "43 129.15261840820312\n",
      "44 85.53962707519531\n",
      "45 106.29557800292969\n",
      "46 143.34967041015625\n",
      "47 144.3863983154297\n",
      "48 65.79559326171875\n",
      "49 75.1761474609375\n",
      "50 172.61277770996094\n",
      "51 86.88871002197266\n",
      "52 124.29984283447266\n",
      "53 101.73066711425781\n",
      "54 59.72722244262695\n",
      "55 75.81473541259766\n",
      "56 116.95375061035156\n",
      "57 59.171852111816406\n",
      "58 55.01758575439453\n",
      "59 146.52041625976562\n",
      "60 130.96575927734375\n",
      "61 45.96879959106445\n",
      "62 32.279293060302734\n",
      "63 24.6340389251709\n",
      "64 47.86601638793945\n",
      "65 48.93090057373047\n",
      "66 40.17915725708008\n",
      "67 68.82254028320312\n",
      "68 44.70439147949219\n",
      "69 100.93174743652344\n",
      "70 62.3502082824707\n",
      "71 59.37782287597656\n",
      "72 21.11103630065918\n",
      "73 21.91160011291504\n",
      "74 28.48795509338379\n",
      "75 29.39084243774414\n",
      "76 58.49665069580078\n",
      "77 28.85732650756836\n",
      "78 21.942691802978516\n",
      "79 38.26899719238281\n",
      "80 68.53211975097656\n",
      "81 22.83111000061035\n",
      "82 18.85829734802246\n",
      "83 14.973267555236816\n",
      "84 11.174481391906738\n",
      "85 13.560577392578125\n",
      "86 11.81978988647461\n",
      "87 8.73492431640625\n",
      "88 26.42474365234375\n",
      "89 20.353618621826172\n",
      "90 18.52643585205078\n",
      "91 6.633148193359375\n",
      "92 23.95047378540039\n",
      "93 35.05838394165039\n",
      "94 14.273778915405273\n",
      "95 14.157904624938965\n",
      "96 17.790451049804688\n",
      "97 21.586811065673828\n",
      "98 11.05992603302002\n",
      "99 8.941559791564941\n",
      "100 8.299070358276367\n",
      "101 13.091287612915039\n",
      "102 10.729557037353516\n",
      "103 12.006824493408203\n",
      "104 7.53727912902832\n",
      "105 26.06623077392578\n",
      "106 17.503868103027344\n",
      "107 10.592535018920898\n",
      "108 10.157336235046387\n",
      "109 25.766931533813477\n",
      "110 6.38335657119751\n",
      "111 4.262903213500977\n",
      "112 7.648257255554199\n",
      "113 12.08148193359375\n",
      "114 5.979007720947266\n",
      "115 4.4020256996154785\n",
      "116 6.734530448913574\n",
      "117 11.322892189025879\n",
      "118 6.857728958129883\n",
      "119 12.930710792541504\n",
      "120 14.157960891723633\n",
      "121 6.2594428062438965\n",
      "122 5.542355537414551\n",
      "123 8.598045349121094\n",
      "124 5.983794689178467\n",
      "125 17.989389419555664\n",
      "126 8.058558464050293\n",
      "127 9.6655912399292\n",
      "128 30.592342376708984\n",
      "129 6.035369873046875\n",
      "130 7.241051197052002\n",
      "131 7.397075653076172\n",
      "132 48.55146026611328\n",
      "133 41.465179443359375\n",
      "134 17.115276336669922\n",
      "135 47.56293487548828\n",
      "136 121.36197662353516\n",
      "137 4.905513286590576\n",
      "138 15.101166725158691\n",
      "139 59.011505126953125\n",
      "140 54.0424919128418\n",
      "141 17.3123836517334\n",
      "142 26.46015167236328\n",
      "143 16.8692684173584\n",
      "144 20.599994659423828\n",
      "145 15.773665428161621\n",
      "146 17.12499237060547\n",
      "147 18.040626525878906\n",
      "148 16.722444534301758\n",
      "149 9.399881362915039\n",
      "150 14.97823429107666\n",
      "151 12.167317390441895\n",
      "152 20.759572982788086\n",
      "153 5.68414831161499\n",
      "154 10.038811683654785\n",
      "155 10.861998558044434\n",
      "156 21.64737892150879\n",
      "157 9.696731567382812\n",
      "158 7.948400497436523\n",
      "159 3.7130942344665527\n",
      "160 3.710331439971924\n",
      "161 18.523765563964844\n",
      "162 2.2970616817474365\n",
      "163 2.1618881225585938\n",
      "164 2.69789719581604\n",
      "165 14.11960506439209\n",
      "166 6.2074713706970215\n",
      "167 7.938089370727539\n",
      "168 20.560100555419922\n",
      "169 14.686136245727539\n",
      "170 5.01277494430542\n",
      "171 8.045448303222656\n",
      "172 12.988056182861328\n",
      "173 7.259971618652344\n",
      "174 5.65705680847168\n",
      "175 6.18259334564209\n",
      "176 1.4474716186523438\n",
      "177 0.9445989727973938\n",
      "178 1.3723742961883545\n",
      "179 16.573848724365234\n",
      "180 15.158106803894043\n",
      "181 1.724868655204773\n",
      "182 17.403209686279297\n",
      "183 17.577173233032227\n",
      "184 4.429436683654785\n",
      "185 3.8004775047302246\n",
      "186 19.654678344726562\n",
      "187 1.7090647220611572\n",
      "188 1.742244839668274\n",
      "189 18.726022720336914\n",
      "190 6.353829383850098\n",
      "191 4.675691604614258\n",
      "192 9.344379425048828\n",
      "193 32.04313659667969\n",
      "194 5.216421127319336\n",
      "195 2.0605688095092773\n",
      "196 53.417457580566406\n",
      "197 21.23990821838379\n",
      "198 13.728937149047852\n",
      "199 7.135806560516357\n",
      "200 4.097064971923828\n",
      "201 15.225558280944824\n",
      "202 36.947914123535156\n",
      "203 38.142723083496094\n",
      "204 13.153932571411133\n",
      "205 30.53839111328125\n",
      "206 68.837158203125\n",
      "207 50.52625274658203\n",
      "208 18.65660858154297\n",
      "209 6.661760330200195\n",
      "210 18.125940322875977\n",
      "211 76.53976440429688\n",
      "212 27.735694885253906\n",
      "213 17.165803909301758\n",
      "214 35.29255676269531\n",
      "215 34.60930633544922\n",
      "216 12.997406959533691\n",
      "217 6.9353108406066895\n",
      "218 22.18457794189453\n",
      "219 19.202802658081055\n",
      "220 9.773459434509277\n",
      "221 15.829066276550293\n",
      "222 12.880936622619629\n",
      "223 13.543567657470703\n",
      "224 15.259323120117188\n",
      "225 8.35001277923584\n",
      "226 8.828871726989746\n",
      "227 5.825850963592529\n",
      "228 9.479192733764648\n",
      "229 8.477706909179688\n",
      "230 7.973783016204834\n",
      "231 11.133684158325195\n",
      "232 4.931407928466797\n",
      "233 9.045116424560547\n",
      "234 3.1321587562561035\n",
      "235 8.448887825012207\n",
      "236 10.499582290649414\n",
      "237 2.718763828277588\n",
      "238 5.049918174743652\n",
      "239 4.809737205505371\n",
      "240 4.301759719848633\n",
      "241 5.610156536102295\n",
      "242 6.308281898498535\n",
      "243 4.1290059089660645\n",
      "244 5.744019508361816\n",
      "245 2.522679090499878\n",
      "246 5.239029407501221\n",
      "247 1.9183320999145508\n",
      "248 2.5423190593719482\n",
      "249 1.947079062461853\n",
      "250 1.460390329360962\n",
      "251 10.135571479797363\n",
      "252 3.8298206329345703\n",
      "253 2.4991209506988525\n",
      "254 8.714481353759766\n",
      "255 0.7453427910804749\n",
      "256 5.07490348815918\n",
      "257 1.2141449451446533\n",
      "258 2.570131301879883\n",
      "259 2.9318695068359375\n",
      "260 4.213550090789795\n",
      "261 1.6006908416748047\n",
      "262 3.433987855911255\n",
      "263 1.36795973777771\n",
      "264 2.0484228134155273\n",
      "265 5.139194011688232\n",
      "266 4.094914436340332\n",
      "267 0.5084666013717651\n",
      "268 1.0287623405456543\n",
      "269 1.711717963218689\n",
      "270 2.9472110271453857\n",
      "271 1.9714449644088745\n",
      "272 2.3783626556396484\n",
      "273 2.4659221172332764\n",
      "274 2.1315529346466064\n",
      "275 4.403046131134033\n",
      "276 2.030703067779541\n",
      "277 2.572873830795288\n",
      "278 1.7157734632492065\n",
      "279 1.6571964025497437\n",
      "280 1.6645125150680542\n",
      "281 1.3227953910827637\n",
      "282 0.5140508413314819\n",
      "283 1.7472254037857056\n",
      "284 1.6834425926208496\n",
      "285 1.6289293766021729\n",
      "286 1.2167471647262573\n",
      "287 1.1068568229675293\n",
      "288 1.9608269929885864\n",
      "289 1.2940133810043335\n",
      "290 1.3362423181533813\n",
      "291 1.2130392789840698\n",
      "292 1.0692551136016846\n",
      "293 0.8940180540084839\n",
      "294 0.9531193375587463\n",
      "295 1.096500039100647\n",
      "296 0.9148653149604797\n",
      "297 0.49007970094680786\n",
      "298 0.5073501467704773\n",
      "299 1.1085115671157837\n",
      "300 0.3726605772972107\n",
      "301 2.3544468879699707\n",
      "302 0.29761746525764465\n",
      "303 1.0307930707931519\n",
      "304 1.478633165359497\n",
      "305 0.4445687532424927\n",
      "306 0.9900251626968384\n",
      "307 0.9138017892837524\n",
      "308 0.9485486149787903\n",
      "309 1.0571056604385376\n",
      "310 1.777917742729187\n",
      "311 0.18750882148742676\n",
      "312 0.7089849710464478\n",
      "313 0.7480846643447876\n",
      "314 1.4417575597763062\n",
      "315 1.1808587312698364\n",
      "316 0.2219386100769043\n",
      "317 1.4299887418746948\n",
      "318 0.6557825803756714\n",
      "319 0.7477211952209473\n",
      "320 0.46950727701187134\n",
      "321 0.19226911664009094\n",
      "322 0.9169943332672119\n",
      "323 0.19521750509738922\n",
      "324 0.1688089370727539\n",
      "325 0.13751250505447388\n",
      "326 0.4771142601966858\n",
      "327 0.10676909238100052\n",
      "328 0.45960888266563416\n",
      "329 0.43291202187538147\n",
      "330 1.0297093391418457\n",
      "331 0.9448922872543335\n",
      "332 0.3629891872406006\n",
      "333 0.8252056837081909\n",
      "334 0.34018367528915405\n",
      "335 0.9948761463165283\n",
      "336 0.9329621195793152\n",
      "337 0.3697912096977234\n",
      "338 0.3872857391834259\n",
      "339 0.20993195474147797\n",
      "340 1.1991240978240967\n",
      "341 0.2719692587852478\n",
      "342 0.8742164969444275\n",
      "343 1.0270812511444092\n",
      "344 0.7671380043029785\n",
      "345 0.1481439769268036\n",
      "346 0.893271803855896\n",
      "347 0.31928056478500366\n",
      "348 0.3313869535923004\n",
      "349 0.1022152304649353\n",
      "350 0.9232559204101562\n",
      "351 0.326363742351532\n",
      "352 0.7121978998184204\n",
      "353 0.3234184980392456\n",
      "354 0.6395424604415894\n",
      "355 0.8581222891807556\n",
      "356 0.3098759949207306\n",
      "357 0.6775155663490295\n",
      "358 0.2539510428905487\n",
      "359 0.15575887262821198\n",
      "360 0.2440899759531021\n",
      "361 0.6347056031227112\n",
      "362 0.22262483835220337\n",
      "363 0.5561510324478149\n",
      "364 0.7390697002410889\n",
      "365 0.18898756802082062\n",
      "366 0.16469618678092957\n",
      "367 0.7025699019432068\n",
      "368 0.21785186231136322\n",
      "369 0.6074451208114624\n",
      "370 0.11988374590873718\n",
      "371 0.10702061653137207\n",
      "372 0.6505794525146484\n",
      "373 0.6234985589981079\n",
      "374 0.30263224244117737\n",
      "375 0.3053656220436096\n",
      "376 0.7303479313850403\n",
      "377 0.5213099718093872\n",
      "378 0.5827130079269409\n",
      "379 0.10196658968925476\n",
      "380 0.10109327733516693\n",
      "381 0.42028680443763733\n",
      "382 0.3142886459827423\n",
      "383 0.3703463673591614\n",
      "384 1.1417104005813599\n",
      "385 0.14800922572612762\n",
      "386 0.11533952504396439\n",
      "387 0.08484320342540741\n",
      "388 1.0570040941238403\n",
      "389 0.5378048419952393\n",
      "390 0.4564591646194458\n",
      "391 0.10820932686328888\n",
      "392 1.7337355613708496\n",
      "393 0.37765058875083923\n",
      "394 0.0487627238035202\n",
      "395 1.6770281791687012\n",
      "396 0.4311862587928772\n",
      "397 0.0862501785159111\n",
      "398 0.8666533827781677\n",
      "399 0.42685285210609436\n",
      "400 0.06945367902517319\n",
      "401 0.345635324716568\n",
      "402 0.5700496435165405\n",
      "403 0.30508798360824585\n",
      "404 0.7034467458724976\n",
      "405 0.6738345623016357\n",
      "406 0.4046749174594879\n",
      "407 0.3315460979938507\n",
      "408 0.4669913649559021\n",
      "409 0.07079246640205383\n",
      "410 1.15006422996521\n",
      "411 0.614699125289917\n",
      "412 0.2368127405643463\n",
      "413 1.0343761444091797\n",
      "414 0.5608914494514465\n",
      "415 0.9850110411643982\n",
      "416 0.5886055827140808\n",
      "417 0.6073133945465088\n",
      "418 0.8423069715499878\n",
      "419 0.8534082174301147\n",
      "420 0.6962601542472839\n",
      "421 0.5000243186950684\n",
      "422 0.7002085447311401\n",
      "423 1.5567837953567505\n",
      "424 0.6147753596305847\n",
      "425 0.7098458409309387\n",
      "426 0.3985782265663147\n",
      "427 1.354013442993164\n",
      "428 0.32842329144477844\n",
      "429 0.7237944006919861\n",
      "430 0.7640761733055115\n",
      "431 0.5823543667793274\n",
      "432 0.5030897855758667\n",
      "433 0.2870178818702698\n",
      "434 0.6908129453659058\n",
      "435 0.2566046416759491\n",
      "436 1.5584962368011475\n",
      "437 0.329894095659256\n",
      "438 0.2646970748901367\n",
      "439 0.21310651302337646\n",
      "440 2.0284857749938965\n",
      "441 0.9086287021636963\n",
      "442 1.0392786264419556\n",
      "443 1.79252290725708\n",
      "444 0.7138831615447998\n",
      "445 0.9214880466461182\n",
      "446 0.29558634757995605\n",
      "447 1.164609432220459\n",
      "448 1.5089495182037354\n",
      "449 0.6797361969947815\n",
      "450 1.6204216480255127\n",
      "451 2.1295502185821533\n",
      "452 0.6513038277626038\n",
      "453 1.3338077068328857\n",
      "454 0.3648119866847992\n",
      "455 1.279077410697937\n",
      "456 0.22431999444961548\n",
      "457 0.44280144572257996\n",
      "458 0.6320599317550659\n",
      "459 0.5582605004310608\n",
      "460 0.415494829416275\n",
      "461 0.5604108572006226\n",
      "462 0.4896930754184723\n",
      "463 0.3060612678527832\n",
      "464 0.24912886321544647\n",
      "465 0.6892263293266296\n",
      "466 0.617631196975708\n",
      "467 0.4095022678375244\n",
      "468 0.3759896755218506\n",
      "469 0.27507728338241577\n",
      "470 0.548978865146637\n",
      "471 0.7486345767974854\n",
      "472 0.16871631145477295\n",
      "473 0.46913066506385803\n",
      "474 0.46339482069015503\n",
      "475 0.11105219274759293\n",
      "476 0.24939249455928802\n",
      "477 0.07059211283922195\n",
      "478 0.23351503908634186\n",
      "479 0.2068948745727539\n",
      "480 0.5488357543945312\n",
      "481 0.2688257694244385\n",
      "482 0.7807399034500122\n",
      "483 0.442052960395813\n",
      "484 0.09677202999591827\n",
      "485 0.1618567407131195\n",
      "486 0.5541839599609375\n",
      "487 0.6882810592651367\n",
      "488 0.1706608086824417\n",
      "489 0.39741796255111694\n",
      "490 0.6057465076446533\n",
      "491 0.1706366389989853\n",
      "492 0.0953909307718277\n",
      "493 0.16731366515159607\n",
      "494 0.1744060218334198\n",
      "495 0.45428940653800964\n",
      "496 0.11222952604293823\n",
      "497 0.08790460228919983\n",
      "498 0.7630404233932495\n",
      "499 0.16183535754680634\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        \"\"\"\n",
    "        在构造函数中，我们构造了三个nn.Linear实例，它们将在前向传播时被使用。\n",
    "        \"\"\"\n",
    "        super(DynamicNet,self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in,H)\n",
    "        self.middle_linear = torch.nn.Linear(H,H)\n",
    "        self.output_linear = torch.nn.Linear(H,D_out)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        对于模型的前向传播，我们随机选择0、1、2、3，\n",
    "        并重用了多次计算隐藏层的middle_linear模块。\n",
    "        由于每个前向传播构建一个动态计算图，\n",
    "        我们可以在定义模型的前向传播时使用常规Python控制流运算符，如循环或条件语句。\n",
    "        在这里，我们还看到，在定义计算图形时多次重用同一个模块是完全安全的。\n",
    "        这是Lua Torch的一大改进，因为Lua Torch中每个模块只能使用一次。\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0,3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "# N是批大小；D是输入维度\n",
    "# H是隐藏层维度；D_out是输出维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 产生输入和输出随机张量\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# 构造我们的损失函数（loss function）和优化器（Optimizer）。\n",
    "# 用平凡的随机梯度下降训练这个奇怪的模型是困难的，所以我们使用了momentum方法。\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4,momentum=0.9)\n",
    "\n",
    "for t in range(500):\n",
    "    # 前向传播：通过向模型传入x计算预测的y\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 计算并打印损失\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 清零梯度，反向传播，更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be203ce0b3afc4f5c37fbac412025d7ed1d67cabe9dd00b1fc8774c6d6d19d70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
