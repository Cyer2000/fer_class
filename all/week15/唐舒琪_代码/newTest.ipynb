{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import os\n",
    "import image_utils\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "pil=torchvision.transforms.ToPILImage()#将tensor数据转换成图片\n",
    "\n",
    "class MyDataSet(data.Dataset):\n",
    "    def __init__(self,phase=\"train\",transform=None,basic_aug=True):\n",
    "        self.phase=phase\n",
    "        self.transform=transform\n",
    "        self.basic_aug=basic_aug\n",
    "        \n",
    "        NAME_COLUMN=0 #图片名字\n",
    "        LABEL_COLUMN=1 #图片标签\n",
    "\n",
    "        df=pd.read_csv(\"datasets/raf-basic/EmoLabel/list_patition_label.txt\",sep=' ',header=None)\n",
    "        if phase==\"train\":\n",
    "            dataset=df[df[NAME_COLUMN].str.startswith('train')]\n",
    "        else:\n",
    "            dataset=df[df[NAME_COLUMN].str.startswith('test')]\n",
    "        file_names=dataset.iloc[:,NAME_COLUMN].values    #所有行获得第一列的文件名字\n",
    "        self.label=dataset.iloc[:,LABEL_COLUMN].values-1 #  0:Surprise, 1:Fear, 2:Disgust, 3:Happiness, 4:Sadness, 5:Anger, 6:Neutral\n",
    "\n",
    "        self.file_paths=[]#使用对齐过的图片进行训练、测试\n",
    "\n",
    "        for f in file_names:\n",
    "            f=f.split(\".\")[0] #只要文件名字，不要后缀名\n",
    "            f=f+\"_aligned.jpg\" #使用对齐后的图片\n",
    "            path=os.path.join('datasets/raf-basic/Image/aligned',f)\n",
    "            self.file_paths.append(path)\n",
    "\n",
    "        self.aug_func=[image_utils.flip_image,image_utils.add_gaussian_noise]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)   #返回一共有多少张图片\n",
    "\n",
    "    def __getitem__(self,idx):   \n",
    "        path=self.file_paths[idx]\n",
    "        image=cv2.imread(path)\n",
    "        # display(pil(image))\n",
    "        image = image[:, :, ::-1]  #读取该张图片并将其转换为RGB格式，原格式为#BGR\n",
    "        label=self.label[idx]  #得到该张图片对应的标签\n",
    "\n",
    "        #如果是训练阶段，就对图片进行随机增强\n",
    "        if self.phase==\"train\":\n",
    "            if self.basic_aug and random.uniform(0,1)>0.5:\n",
    "                #即如果basic_aug为真并且随机数大于0.5，就对该张图片进行随机增强\n",
    "                index=random.randint(0,1) #随机取0或者取1\n",
    "                image=self.aug_func[index](image) #取增强中的随机一种方法进行图片增强\n",
    "        \n",
    "            #然后再对图片进行预处理\n",
    "        if self.transform is not None:\n",
    "            #一系列变换，根据均值标准差进行归一化,随机翻转、随机遮挡\n",
    "            image=self.transform(image)\n",
    "\n",
    "        return image,label   #返回处理过后的图片数据、图片标签以及图片对应的位置\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(scale=(0.02,0.25))])\n",
    "train_dataset=MyDataSet(phase='train',transform=train_transforms,basic_aug=True)\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=64,\n",
    "                                            num_workers=4,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True)\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])        \n",
    "test_dataset=MyDataSet(phase='test',transform=test_transforms,basic_aug=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,\n",
    "                                        batch_size=64,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False,\n",
    "                                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn\n",
    "import torch\n",
    "import einops\n",
    "from torchvision import transforms\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #然后开始定义该网络涉及到的一些需要用的函数\n",
    "        self.patch_embedding=nn.Sequential(\n",
    "            Rearrange(\"b c (pw w) (ph h) -> b c (pw ph) (w h)\",pw=16,ph=16),#将得到的每个小图片的长乘以宽的像素展平，得到256*196的向量\n",
    "            nn.Linear(14*14,14*14), #每张小图片的向量为196，输出也为196\n",
    "        )\n",
    "        # shape: (batch,1, 7*7)\n",
    "        #通过这样的方式就能将改变量加入到该模型的变量中，然后才能自动进行求导\n",
    "        self.class_token=nn.parameter.Parameter(torch.randn(1,3,1,14*14))\n",
    "        # shape: (batch, 4*4+1, 7*7)\n",
    "        self.position_encodings=nn.parameter.Parameter(\n",
    "            torch.randn((1,3,16*16+1,14*14))\n",
    "        )\n",
    "        #使用python自带的transfoermerEncoder结构\n",
    "        #d_model是embedding向量的维数，设置它为7*7=49\n",
    "        #nhead是MSA中self attention的个数，设置nhead=7\n",
    "        #dim_feedforward是隐藏层的隐藏节点个数\n",
    "        #btach_size是将张量的第一维指定为batch\n",
    "        #3:the number of sub-encoder-layers in the encoder (required).\n",
    "        self.transformer_encoder=nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=14*14,nhead=14,dim_feedforward=256,batch_first=True\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "        #最后进行分类的MLP层，由于有十个类，因此需要将最后输出结果变为7个\n",
    "        #nn.LayerNorm是对向量进行归一化，14*14表示对行进行归一化\n",
    "        self.mlp_head=nn.Sequential(nn.LayerNorm(3*14*14),nn.Linear(3*14*14,7))\n",
    "\n",
    "    #下面将定义该网络的前向传播过程\n",
    "    def forward(self,x):\n",
    "        x=self.patch_embedding(x)#首先将该批图片进行embedding，即剪裁和展平、线性变换\n",
    "        batch_size, _ , _,_=x.shape#将X的第一维数赋值给batch_size，即一次输入了多少张图片\n",
    "        #给每张图片(batch_size张图片)矩阵在最后都上class_token，得到class_token\n",
    "        class_token=einops.repeat(\n",
    "            self.class_token,\n",
    "            \"() channels words features -> repeat channels words features\",\n",
    "            repeat=batch_size\n",
    "        )\n",
    "        x = torch.cat((class_token,x),dim=-2)#即在第负二维（行）上进行拼接，然后就变成了257行\n",
    "        x += self.position_encodings #然后再将x加入position_encoding，但是它可以通过训练得到\n",
    "        x=self.transformer_encoder(x)#接下来将加了class_token和position_embeeding的最终向量输入encode\n",
    "        x=x[:,:,0]#只取class_token那部分进行预测，class_token在第一行\n",
    "        x=einops.rearrange(x,\"b c h->(b c) h\")\n",
    "        x=self.mlp_head(x)#利用class_token取进行预测\n",
    "        return x#返回结果\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始构建训练模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,scheduler,criterion,epochs,train_loader):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"第{epoch}轮开始了\")\n",
    "        for batch_idx,(x,y) in enumerate(train_loader):\n",
    "            print(f\"第{batch_idx}次开始了\")\n",
    "            optimizer.zero_grad()\n",
    "            output=model(x)\n",
    "            loss=criterion(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"第{batch_idx}次结束了\")\n",
    "\n",
    "            if batch_idx%10==0:\n",
    "                print(f\"epoch:{epoch},i:{batch_idx*len(x)}/{len(train_loader.dataset)},loss:{loss.item()}\")\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始构建训练参数并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_transformer_model=VisionTransformer()\n",
    "epochs=70\n",
    "batch_size=64\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(vision_transformer_model.parameters(),lr=0.001)\n",
    "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮开始了\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    vision_transformer_model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs,\n",
    "    train_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b44c525ca95e5dbf893da2282eb3ec3f420cb9fa59d94f9af90ca833dc1a37c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
