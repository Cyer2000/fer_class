**WHEN VISION TRANSFORMERS OUTPERFORM RESNETS WITHOUT PRE-TRAINING OR STRONG DATA AUGMENTATIONS**

* 因此，本文从损失几何的角度研究了ViTs和MLP-混合器，旨在提高模型在训练和推理时的数据效率。可视化和Hessian揭示了已收敛模型的极其尖锐的局部最小值。 通过使用最近提出的锐度感知优化器来提高平滑度，我们大幅提高了ViTs和MLP-Mixers在各种任务中的准确性和鲁棒性
* 我们表明，**平滑度的提高归因于前几层的活性神经元的稀疏**。由此产生的ViTs在ImageNet上从头开始训练时，在**没有大规模预训练或强大的数据增强**的情况下，其表现优于类似规模和吞吐量的ResNets。
* ![1641482822946](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1641482822946.png)
* 我们首先从损失景观的角度研究在 ImageNet 上完全训练的架构，并得出以下发现：
  * 首先，损失景观的可视化和 Hessian 矩阵表明，**Transformer 和 MLP-Mixers 在极其尖锐的局部最小值处收敛，其最大主曲率几乎比 ResNet 大一个数量级**。当梯度从最后一层反向传播到第一层时，这种效应就会累积，并且初始嵌入层受到相应的次对角 Hessian 的最大特征值的影响。
  * 其次，网络都有非常小的训练误差，**MLP-Mixer 比更多参数的 ViTs 更容易过拟合**（可能是因为 self-attention 的差异）。
  * 第三，我们推测**卷积引起的平移等方差和局部性有助于 ResNets 在对视觉数据进行训练时摆脱不良的局部最小值**。
*  **一阶优化器（例如SGD 和 Adam )只寻找最小化训练误差的模型参数。他们忽略了与泛化相关的高阶信息，例如平坦度**。
*  上述研究和推理将我们引向最近提出的锐度感知最小化器（SAM）在模型训练期间明确平滑损失几何。**SAM 努力寻找一种解决方案，其整个邻域的损失都较低，而不是专注于任何单点**。 由此产生的模型表现出**更平滑的损失情况**，并且它们的**泛化能力**在包括监督、对抗、对比和转移学习在内的不同任务中得到了极大的提升 
*  通过分析一些内在的模型属性，我们发现**SAM之后的模型通过激活更稀疏的神经元（在ImageNet上）来减少Hessian特征值，特别是在前几层。权重规范的增加，意味着常用的权重衰减可能不是一个有效的单独的规范化。**一个侧面的观察是，与ResNets和MLP-Mixers不同，ViTs有极其稀疏的活性神经元，揭示了输入图像斑块的冗余性和网络修剪的能力。另一个有趣的发现是，**ViTs的性能提升也转化为可信的注意力图，其中包含了更多关于语义分割的信息**。最后，我们得出了**SAM和强增强（如mixup）之间的相似之处，即它们都平滑了平均损失的几何形状，并鼓励模型在训练图像之间表现为线性。**
*  已经广泛研究表明，**收敛到曲率很小的平坦区域有利于神经网络的泛化**
*  **MLP-Mixer 更容易陷入尖锐的局部最小值。**
*   **ViT 和 MLP-Mixers 的可训练性较差** **，** **ResNets 都具有出色的可训练性**，然而，我们观察到 ViT 和 MLP-Mixer 的条件数不同，这证实了 ViT 的训练需要格外小心
*   常用的一阶优化器（例如 SGD 、Adam ）仅寻求最小化训练损失L *train* ( w ) 。他们通常忽略高阶信息，例如与泛化相关的曲率
*   由于缺乏视觉数据的归纳偏差，ViTs 和 MLPs 放大了一阶优化器的这种缺点，导致损失场景过于尖锐和泛化能力差。我们假设在**收敛时平滑损失景观可以显着提高那些无卷积架构的泛化能力，导致我们最近提出的锐度感知最小化器 (SAM)明确避免了锐度最小值.** 
*  ![1641560482609](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1641560482609.png)
*  ViT 的活跃神经元非常稀疏
